<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- saved from url=(0057)http://blog.chinaunix.net/u2/78225/showart.php?id=1270103 -->
<HTML><HEAD><TITLE>Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时</TITLE>
<META http-equiv=Content-Type content="text/html; charset=gbk"><LINK 
href="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/index.css" 
rel=stylesheet></LINK><LINK title="ChinaUnix Blog RSS Feed" 
href="http://blog.chinaunix.net/u/rss.php?id=78225" type=application/rss+xml 
rel=alternate></LINK>
<META content="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时" name=keywords>
<META 
content="中国最大的IT技术博客-ChinaUnix博客：Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时" 
name=description>
<META content="MSHTML 6.00.2900.3243" name=GENERATOR></HEAD>
<BODY style="BACKGROUND: #ffffff" leftMargin=0 topMargin=0 align="center" 
marginheight="0" marginwidth="0">
<TABLE style="BORDER-COLLAPSE: collapse; HEIGHT: 25px" height=25 cellSpacing=0 
cellPadding=0 width="100%" align=center 
background="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/tophem1.gif" 
border=0>
  <TBODY>
  <TR>
    <TD id=tool-bar noWrap align=left>&nbsp; <A 
      href="http://blog.chinaunix.net/" target=_blank>博客首页</A> <A 
      href="http://blog.chinaunix.net/register.php" target=_blank>注册</A> <A 
      href="http://bbs.chinaunix.net/forumdisplay.php?fid=51" 
      target=_blank>建议与交流</A> <A href="http://blog.chinaunix.net/top/" 
      target=_blank>排行榜</A> <A 
      onclick="NewWindows('http://www.cublog.cn/addlink.php?url='+location.href+'&amp;title='+document.title);return false;" 
      href="http://blog.chinaunix.net/u2/78225/" target=_blank>加入友情链接</A> </TD>
    <FORM id=loginForm action=/search.php method=get target=_blank>
    <TD noWrap align=right><IMG id=starimg height=12 alt="" 
      src="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/userstar.gif" 
      width=55 border=0> <A id=star title=给此博客推荐值 
      onclick="NewWindows(this.href);return false;" 
      href="http://blog.chinaunix.net/u2/star.php?blogid=78225">推荐</A> <A 
      id=complaint title=投诉此博客 onclick="NewWindows(this.href);return false;" 
      href="http://blog.chinaunix.net/u2/complaint.php?blogid=78225">投诉</A> 
      搜索：<INPUT name=q> <INPUT class=button1 type=submit value=搜索> <A 
      href="http://blog.chinaunix.net/help/">帮助</A></TD></FORM></TR></TBODY></TABLE>
<SCRIPT language=javascript>
<!--

navHover = function() {
var lis = document.getElementById("navmenu").getElementsByTagName("LI");
for (var i=0; i<lis.length; i++) {
lis[i].onmouseover=function() {
this.className+=" iehover";
}
lis[i].onmouseout=function() {
this.className=this.className.replace(new RegExp(" iehover\\b"), "");
}
}
}

function NewWindows(shref){
var xx=(window.screen.width-450)/2;
var yy=(window.screen.height-200)/2;
pp=window.open(shref,"win","menubar=no,location=no,resizable=no,scrollbars=no,status=no,left="+xx+",top="+yy+",Width=450,Height=200");
}
function $(s){return document.getElementById(s);}
//-->
</SCRIPT>

<TABLE 
style="BACKGROUND-IMAGE: url(http://www.cublog.cn/templates/newgreen/images/bg_top.gif); BACKGROUND-REPEAT: no-repeat; BORDER-COLLAPSE: collapse" 
height=143 cellSpacing=0 cellPadding=0 width="100%" align=center bgColor=#187218 
border=0>
  <TBODY>
  <TR>
    <TD width=360></TD>
    <TD align=middle width=500>
      <P style="MARGIN: 5px; LINE-HEIGHT: 150%"><FONT style="FONT-SIZE: 14pt" 
      color=#ffffff><B>
      <P style="MARGIN: 5px; LINE-HEIGHT: 150%"><FONT style="FONT-SIZE: 14px" 
      color=#ffffff><B>嵌入式驱动进行时 </B></FONT></P></B></FONT>
      <P></P></TD>
    <TD width=360>学习学习再学习！</TD></TR>
  <TR>
    <TD colSpan=3>
      <TABLE style="BORDER-COLLAPSE: collapse" borderColor=#111111 cellSpacing=0 
      cellPadding=0 width=980 border=0>
        <TBODY>
        <TR>
          <TD></TD></TR></TBODY></TABLE></TD></TR></TBODY></TABLE>
<TABLE style="BORDER-COLLAPSE: collapse" height=27 cellSpacing=0 cellPadding=0 
width="100%" align=center bgColor=#ffffff 
background="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/bg_menu.gif" 
border=0>
  <TBODY>
  <TR>
    <TD align=middle width=30><IMG height=29 alt="" 
      src="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/img_menu_left.gif" 
      width=26 border=0></TD>
    <TD width=200><A class=list1 href="http://yuchuan2008.cublog.cn/" 
      target=_blank>yuchuan2008.cublog.cn</A> </TD>
    <TD style="COLOR: #2a5200" align=right width=750>
      <UL id=navmenu>
        <LI class=ul0><A class=list1 href="http://control.cublog.cn/" 
        target=_blank>管理博客</A> </LI>
        <LI class=ul0><A class=list1 
        href="http://control.cublog.cn/article_new.php" target=_blank>发表文章</A> 
        </LI>
        <LI class=ul0><A class=list1 
        href="http://blog.chinaunix.net/u2/78225/guestbook.html">留言</A> </LI>
        <LI class=ul0><A class=list1 
        href="http://blog.chinaunix.net/u2/78225/links.html">收藏夹</A> 
        <!-- 0 --></LI>
        <LI class=ul0><A class=list1 
        href="http://blog.chinaunix.net/u2/78225/group.html">博客圈</A> </LI>
        <LI class=ul0><A class=list1 
        href="http://blog.chinaunix.net/u2/78225/music.html">音乐</A> 
        <!-- 0 --></LI>
        <LI class=ul0><A class=list1 
        href="http://blog.chinaunix.net/u2/78225/photo.html">相册</A> 
        <!-- 0 --></LI>
        <LI class=ul0><A class=list1 
        href="http://blog.chinaunix.net/u2/78225/article.html">文章</A> 
        <UL class=ul1>
          <LI><A href="http://blog.chinaunix.net/u2/78225/article_96075.html">・ 
          Bootloader（转载）<!-- a96075 --></A><!-- 96075 --> 
          <LI><A href="http://blog.chinaunix.net/u2/78225/article_95828.html">・ 
          嵌入式C语言基础（转载）<!-- a95828 --></A><!-- 95828 --> 
          <LI><A href="http://blog.chinaunix.net/u2/78225/article_95774.html">・ 
          Linux设备驱动（转载）&nbsp;&nbsp;&nbsp;<FONT face="Wingdings 3">}</FONT></A>
          <UL class=ul2>
            <LI><A 
            href="http://blog.chinaunix.net/u2/78225/article_96083.html">・ LDD3<!-- a96083 --></A><!-- 96083 --> 
            <LI><A 
            href="http://blog.chinaunix.net/u2/78225/article_96060.html">・ 
            Linux设备驱动理论<!-- a96060 --></A><!-- 96060 --> 
            <LI><A 
            href="http://blog.chinaunix.net/u2/78225/article_95966.html">・ 
            Linux字符设备驱动<!-- a95966 --></A><!-- 95966 --> 
            <LI><A 
            href="http://blog.chinaunix.net/u2/78225/article_95967.html">・ 
            Linux块设备驱动<!-- a95967 --></A><!-- 95967 --> 
            <LI><A 
            href="http://blog.chinaunix.net/u2/78225/article_95969.html">・ 
            Linux总线驱动<!-- a95969 --></A><!-- 95969 --> 
            <LI><A 
            href="http://blog.chinaunix.net/u2/78225/article_95968.html">・ 
            Linux网络设备驱动<!-- a95968 --></A><!-- 95968 --> 
            <LI><A 
            href="http://blog.chinaunix.net/u2/78225/article_96065.html">・ 
            Linux复杂设备驱动<!-- a96065 --></A><!-- 96065 --> </LI></UL>
          <LI><A href="http://blog.chinaunix.net/u2/78225/article_96073.html">・ 
          Linux内核（转载）<!-- a96073 --></A><!-- 96073 --> 
          <LI><A href="http://blog.chinaunix.net/u2/78225/article_96055.html">・ 
          学习&amp;&amp;工作&nbsp;&nbsp;&nbsp;<FONT face="Wingdings 3">}</FONT></A>
          <UL class=ul2>
            <LI><A 
            href="http://blog.chinaunix.net/u2/78225/article_96507.html">・ 
            嵌入式系统开发<!-- a96507 --></A><!-- 96507 --> 
            <LI><A 
            href="http://blog.chinaunix.net/u2/78225/article_96918.html">・ 
            Embest 2410<!-- a96918 --></A><!-- 96918 --> 
            <LI><A 
            href="http://blog.chinaunix.net/u2/78225/article_96639.html">・ 
            LINUX下C应用编程<!-- a96639 --></A><!-- 96639 --> 
            <LI><A 
            href="http://blog.chinaunix.net/u2/78225/article_96508.html">・ 
            Linux驱动开发<!-- a96508 --></A><!-- 96508 --> 
            <LI><A 
            href="http://blog.chinaunix.net/u2/78225/article_96509.html">・ 测试技术<!-- a96509 --></A><!-- 96509 --> </LI></UL>
          <LI><A href="http://blog.chinaunix.net/u2/78225/article_95777.html">・ 
          交叉编译（转载）<!-- a95777 --></A><!-- 95777 --> 
          <LI><A href="http://blog.chinaunix.net/u2/78225/article_96080.html">・ 
          ARM技术（转载）<!-- a96080 --></A><!-- 96080 --> 
          <LI><A href="http://blog.chinaunix.net/u2/78225/article_97102.html">・ 
          嵌入式系统开发（转载）<!-- a97102 --></A><!-- 97102 --> 
          <LI><A href="http://blog.chinaunix.net/u2/78225/article_95775.html">・ 
          Linux基础（转载）<!-- a95775 --></A><!-- 95775 --> 
          <LI><A href="http://blog.chinaunix.net/u2/78225/article_95854.html">・ 
          Linux应用程序（转载）<!-- a95854 --></A><!-- 95854 --> 
          <LI><A href="http://blog.chinaunix.net/u2/78225/article_96053.html">・ 
          其他<!-- a96053 --></A><!-- 96053 --> </LI></UL></LI>
        <LI class=ul0><A class=list1 
        href="http://blog.chinaunix.net/u2/78225/index.html">首页</A> </LI></UL></TD>
    <TD width=10></TD></TR>
  <TR>
    <TD colSpan=4>
      <TABLE style="BORDER-COLLAPSE: collapse" borderColor=#111111 cellSpacing=0 
      cellPadding=0 width=980 border=0>
        <TBODY>
        <TR>
          <TD></TD></TR></TBODY></TABLE></TD></TR></TBODY></TABLE>
<SCRIPT language=javascript>
function $(s){return document.getElementById(s);}
function ShowHideDiv(divid,iImg){
if($(divid).style.display == "none"){
iImg.src="../../templates/newgreen/images/dot2.gif";
$(divid).style.display = "block";
iImg.title="收起";
}else{
iImg.src="../../templates/newgreen/images/dot4.gif";
$(divid).style.display = "none";
iImg.title="展开";
}
}
navHover();
</SCRIPT>

<TABLE style="BORDER-COLLAPSE: collapse" borderColor=#111111 cellSpacing=0 
cellPadding=0 width="100%" border=0>
  <TBODY>
  <TR>
    <TD height=3></TD></TR></TBODY></TABLE><BR>
<TABLE style="BORDER-COLLAPSE: collapse" borderColor=#111111 cellSpacing=0 
cellPadding=0 width="90%" align=center border=0>
  <TBODY>
  <TR>
    <TD width=18 height=28><IMG alt="" 
      src="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/bg_art_left_top.gif" 
      border=0></TD>
    <TD 
    background="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/bg_art_top.gif">
      <P style="MARGIN: 5px; LINE-HEIGHT: 150%"></P></TD>
    <TD width=18 height=28><IMG alt="" 
      src="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/bg_art_right_top.gif" 
      border=0></TD></TR>
  <TR>
    <TD width=18 
    background="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/bg_art_left.gif"></TD>
    <TD align=middle bgColor=#f5fdee><BR><FONT style="FONT-SIZE: 14pt" 
      color=#295200><B>Linux Device Driver书籍（6）并发和竞争情况</B></FONT> 
      <TABLE style="BORDER-COLLAPSE: collapse" borderColor=#a5bd6b cellSpacing=1 
      cellPadding=0 width="100%" border=1>
        <TBODY>
        <TR>
          <TD align=middle>
            <TABLE style="BORDER-COLLAPSE: collapse; WORD-WRAP: break-word" 
            cellSpacing=0 cellPadding=0 width="100%" border=0>
              <TBODY>
              <TR>
                <TD align=middle>
                  <TABLE 
                  style="BORDER-COLLAPSE: collapse; WORD-WRAP: break-word" 
                  cellSpacing=0 cellPadding=0 width="100%" border=0>
                    <TBODY>
                    <TR>
                      <TD>
                        <DIV id=art style="MARGIN: 15px">
                        <DIV>第 6 章 高级字符驱动操作</DIV>
                        <DIV>
                        <P>在第 3 章, 我们建立了一个完整的设备驱动, 用户可用来写入和读取. 
                        但是一个真正的设备常常提供比同步读和写更多的功能. 现在我们已装备有调试工具如果发生错误, 
                        并且一个牢固的并发的理解来帮助避免事情进入错误-- 我们可安全地前进并且创建一个更高级的驱动.</P>
                        <P>本章检查几个你需要理解的概念来编写全特性的字符设备驱动. 我们从实现 ioctl 系统调用开始, 
                        它是用作设备控制的普通接口. 接着我们进入各种和用户空间同步的方法; 在本章结尾, 
                        你有一个充分的认识对于如何使进程睡眠(并且唤醒它们), 实现非阻塞的 I/O, 
                        并且通知用户空间当你的设备可用来读或写. 我们以查看如何在驱动中实现几个不同的设备存取策略来结束.</P>
                        <P>这里讨论的概念通过 scull 驱动的几个修改版本来演示. 再一次, 所有的都使用内存中的虚拟设备来实现, 
                        因此你可自己试验这些代码而不必使用任何特别的硬件. 到此为止, 你可能在想亲手使用真正的硬件, 
                        但是那将必须等到第 9 章.</P>
                        <DIV class=sect1 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H2 class=title style="CLEAR: both"><A 
                        name=ioctl.sect1></A>6.1.&nbsp;ioctl 
                        接口</H2></DIV></DIV></DIV>
                        <P>大部分驱动需要 -- 除了读写设备的能力 -- 通过设备驱动进行各种硬件控制的能力. 
                        大部分设备可进行超出简单的数据传输之外的操作; 用户空间必须常常能够请求, 例如, 设备锁上它的门, 
                        弹出它的介质, 报告错误信息, 改变波特率, 或者自我销毁. 这些操作常常通过 ioctl 方法来支持, 
                        它通过相同名子的系统调用来实现.</P>
                        <P>在用户空间, ioctl 系统调用有下面的原型:</P><PRE class=programlisting>int ioctl(int fd, unsigned long cmd, ...); 
</PRE>
                        <P>这个原型由于这些点而凸现于 Unix 系统调用列表, 这些点常常表示函数有数目不定的参数. 在实际系统中, 
                        但是, 一个系统调用不能真正有变数目的参数. 系统调用必须有一个很好定义的原型, 
                        因为用户程序可存取它们只能通过硬件的"门". 因此, 原型中的点不表示一个变数目的参数, 
                        而是一个单个可选的参数, 传统上标识为 char *argp. 这些点在那里只是为了阻止在编译时的类型检查. 第 
                        3 个参数的实际特点依赖所发出的特定的控制命令( 第 2 个参数 ). 一些命令不用参数, 一些用一个整数值, 
                        以及一些使用指向其他数据的指针. 使用一个指针是传递任意数据到 ioctl 调用的方法; 
                        设备接着可与用户空间交换任何数量的数据.</P>
                        <P>ioctl 调用的非结构化特性使它在内核开发者中失宠. 每个 ioctl 命令, 基本上, 是一个单独的, 
                        常常无文档的系统调用, 并且没有方法以任何类型的全面的方式核查这些调用. 也难于使非结构化的 ioctl 
                        参数在所有系统上一致工作; 例如, 考虑运行在 32-位模式的一个用户进程的 64-位 系统. 结果, 
                        有很大的压力来实现混杂的控制操作, 只通过任何其他的方法. 
                        可能的选择包括嵌入命令到数据流(本章稍后我们将讨论这个方法)或者使用虚拟文件系统, 要么是 sysfs 
                        要么是设备特定的文件系统. (我们将在 14 章看看 sysfs). 但是, 事实是 ioctl 
                        常常是最容易的和最直接的选择,对于真正的设备操作.</P>
                        <P>ioctl 驱动方法有和用户空间版本不同的原型:</P><PRE class=programlisting>int (*ioctl) (struct inode *inode, struct file *filp, unsigned int cmd, unsigned long arg);
</PRE>
                        <P>inode 和 filp 指针是对应应用程序传递的文件描述符 fd 的值, 和传递给 open 
                        方法的相同参数. cmd 参数从用户那里不改变地传下来, 并且可选的参数 arg 参数以一个 unsigned 
                        long 的形式传递, 不管它是否由用户给定为一个整数或一个指针. 如果调用程序不传递第 3 个参数, 
                        被驱动操作收到的 arg 值是无定义的. 因为类型检查在这个额外参数上被关闭, 
                        编译器不能警告你如果一个无效的参数被传递给 ioctl, 并且任何关联的错误将难以查找.</P>
                        <P>如果你可能想到的, 大部分 ioctl 实现包括一个大的 switch 语句来根据 cmd 参数, 
                        选择正确的做法. 不同的命令有不同的数值, 它们常常被给予符号名来简化编码. 符号名通过一个预处理定义来安排. 
                        定制的驱动常常声明这样的符号在它们的头文件中; scull.h 为 scull 声明它们. 用户程序必须, 
                        当然, 包含那个头文件来存取这些符号.</P>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=ChoosingtheioctlCommands.sect2></A>6.1.1.&nbsp;选择 
                        ioctl 命令</H3></DIV></DIV></DIV>
                        <P>在为 ioctl 编写代码之前, 你需要选择对应命令的数字. 
                        许多程序员的第一个本能的反应是选择一组小数从0或1开始, 并且从此开始向上. 但是, 有充分的理由不这样做. 
                        ioctl 命令数字应当在这个系统是唯一的, 为了阻止向错误的设备发出正确的命令而引起的错误. 
                        这样的不匹配不会不可能发生, 并且一个程序可能发现它自己试图改变一个非串口输入系统的波特率, 例如一个 FIFO 
                        或者一个音频设备. 如果这样的 ioctl 号是唯一的, 这个应用程序得到一个 EINVAL 
                        错误而不是继续做不应当做的事情.</P>
                        <P>为帮助程序员创建唯一的 ioctl 命令代码, 这些编码已被划分为几个位段. Linux 的第一个版本使用 
                        16-位数: 高 8 位是关联这个设备的"魔"数, 低 8 位是一个顺序号, 在设备内唯一. 这样做是因为 
                        Linus 是"无能"的(他自己的话); 一个更好的位段划分仅在后来被设想. 不幸的是, 
                        许多驱动仍然使用老传统. 它们不得不: 
                        改变命令编码会破坏大量的二进制程序,并且这不是内核开发者愿意见到的.</P>
                        <P>根据 Linux 内核惯例来为你的驱动选择 ioctl 号, 你应当首先检查 
                        include/asm/ioctl.h 和 Documentation/ioctl-number.txt. 
                        这个头文件定义你将使用的位段: type(魔数), 序号, 传输方向, 和参数大小. 
                        ioctl-number.txt 文件列举了在内核中使用的魔数,<SUP>[<A 
                        href="http://www.deansys.com/doc/ldd3/ch06.html#ftn.id433758" 
                        name=id433758><FONT color=#0000ff>20</FONT></A>]</SUP> 
                        因此你将可选择你自己的魔数并且避免交叠. 这个文本文件也列举了为什么应当使用惯例的原因.</P>
                        <P>定义 ioctl 命令号的正确方法使用 4 个位段, 它们有下列的含义. 这个列表中介绍的新符号定义在 
                        &lt;linux/ioctl.h&gt;.</P>
                        <DIV class=variablelist>
                        <DL>
                          <DT><SPAN class=term><SPAN>type </SPAN></SPAN>
                          <DD>
                          <P>魔数. 只是选择一个数(在参考了 ioctl-number.txt之后)并且使用它在整个驱动中. 
                          这个成员是 8 位宽(_IOC_TYPEBITS). </P>
                          <DT><SPAN class=term><SPAN>number</SPAN></SPAN> 
                          <DD>
                          <P>序(顺序)号. 它是 8 位(_IOC_NRBITS)宽. </P>
                          <DT><SPAN class=term><SPAN>direction </SPAN></SPAN>
                          <DD>
                          <P>数据传送的方向,如果这个特殊的命令涉及数据传送. 可能的值是 _IOC_NONE(没有数据传输), 
                          _IOC_READ, _IOC_WRITE, 和 _IOC_READ|_IOC_WRITE 
                          (数据在2个方向被传送). 数据传送是从应用程序的观点来看待的; _IOC_READ 意思是从设备读, 
                          因此设备必须写到用户空间. 注意这个成员是一个位掩码, 因此 _IOC_READ 和 _IOC_WRITE 
                          可使用一个逻辑 AND 操作来抽取.</P>
                          <DT><SPAN class=term><SPAN>size </SPAN></SPAN>
                          <DD>
                          <P>涉及到的用户数据的大小. 这个成员的宽度是依赖体系的, 但是常常是 13 或者 14 位. 
                          你可为你的特定体系在宏 _IOC_SIZEBITS 中找到它的值. 你使用这个 size 成员不是强制的 - 
                          内核不检查它 -- 但是它是一个好主意. 正确使用这个成员可帮助检测用户空间程序的错误并使你实现向后兼容, 
                          如果你曾需要改变相关数据项的大小. 如果你需要更大的数据结构, 但是, 你可忽略这个 size 成员. 
                          我们很快见到如何使用这个成员.</P></DD></DL></DIV>
                        <P>头文件 &lt;asm/ioctl.h&gt;, 它包含在 &lt;linux/ioctl.h&gt; 
                        中, 定义宏来帮助建立命令号, 如下: _IO(type,nr)(给没有参数的命令), _IOR(type, 
                        nre, datatype)(给从驱动中读数据的), _IOW(type,nr,datatype)(给写数据), 
                        和 _IOWR(type,nr,datatype)(给双向传送). type 和 number 
                        成员作为参数被传递, 并且 size 成员通过应用 sizeof 到 datatype 参数而得到.</P>
                        <P>这个头文件还定义宏, 可被用在你的驱动中来解码这个号: _IOC_DIR(nr), 
                        _IOC_TYPE(nr), _IOC_NR(nr), 和 _IOC_SIZE(nr). 
                        我们不进入任何这些宏的细节, 因为头文件是清楚的, 并且在本节稍后有例子代码展示.</P>
                        <P>这里是一些 ioctl 命令如何在 scull 被定义的. 特别地, 
                        这些命令设置和获得驱动的可配置参数.</P><PRE class=programlisting>/* Use 'k' as magic number */
#define SCULL_IOC_MAGIC 'k'
/* Please use a different 8-bit number in your code */

#define SCULL_IOCRESET _IO(SCULL_IOC_MAGIC, 0)
/*
 * S means "Set" through a ptr,
 * T means "Tell" directly with the argument value
 * G means "Get": reply by setting through a pointer
 * Q means "Query": response is on the return value
 * X means "eXchange": switch G and S atomically
 * H means "sHift": switch T and Q atomically
 */
#define SCULL_IOCSQUANTUM _IOW(SCULL_IOC_MAGIC, 1, int)
#define SCULL_IOCSQSET _IOW(SCULL_IOC_MAGIC, 2, int)
#define SCULL_IOCTQUANTUM _IO(SCULL_IOC_MAGIC, 3)
#define SCULL_IOCTQSET _IO(SCULL_IOC_MAGIC, 4)
#define SCULL_IOCGQUANTUM _IOR(SCULL_IOC_MAGIC, 5, int)
#define SCULL_IOCGQSET _IOR(SCULL_IOC_MAGIC, 6, int)
#define SCULL_IOCQQUANTUM _IO(SCULL_IOC_MAGIC, 7)
#define SCULL_IOCQQSET _IO(SCULL_IOC_MAGIC, 8)
#define SCULL_IOCXQUANTUM _IOWR(SCULL_IOC_MAGIC, 9, int)
#define SCULL_IOCXQSET _IOWR(SCULL_IOC_MAGIC,10, int)
#define SCULL_IOCHQUANTUM _IO(SCULL_IOC_MAGIC, 11)
#define SCULL_IOCHQSET _IO(SCULL_IOC_MAGIC, 12)

#define SCULL_IOC_MAXNR 14
</PRE>
                        <P>真正的源文件定义几个额外的这里没有出现的命令.</P>
                        <P>我们选择实现 2 种方法传递整数参数: 通过指针和通过明确的值(尽管, 由于一个已存在的惯例, ioclt 
                        应当通过指针交换值). 类似地, 2 种方法被用来返回一个整数值:通过指针和通过设置返回值. 
                        这个有效只要返回值是一个正的整数; 如同你现在所知道的, 在从任何系统调用返回时, 一个正值被保留(如同我们在 
                        read 和 write 中见到的), 而一个负值被看作一个错误并且被用来在用户空间设置 
                        errno.<SUP>[<A 
                        href="http://www.deansys.com/doc/ldd3/ch06.html#ftn.id433917" 
                        name=id433917><FONT 
                        color=#0000ff>21</FONT></A>]</SUP></P>
                        <P>"exchange"和"shift"操作对于 scull 没有特别的用处. 
                        我们实现"exchange"来显示驱动如何结合独立的操作到单个的原子的操作, 
                        并且"shift"来连接"tell"和"query". 有时需要象这样的原子的测试-和-设置操作, 特别地, 
                        当应用程序需要设置和释放锁.</P>
                        <P>命令的明确的序号没有特别的含义. 它只用来区分命令. 实际上, 
                        你甚至可使用相同的序号给一个读命令和一个写命令, 因为实际的 ioctl 号在"方向"位是不同的, 
                        但是你没有理由这样做. 我们选择在任何地方不使用命令的序号除了声明中, 因此我们不分配一个返回值给它. 
                        这就是为什么明确的号出现在之前给定的定义中. 这个例子展示了一个使用命令号的方法, 
但是你有自由不这样做.</P>
                        <P>除了少数几个预定义的命令(马上就讨论), ioctl 的 cmd 参数的值当前不被内核使用, 
                        并且在将来也很不可能. 因此, 你可以, 如果你觉得懒, 避免前面展示的复杂的声明并明确声明一组调整数字. 
                        另一方面, 如果你做了, 你不会从使用这些位段中获益, 并且你会遇到困难如果你曾提交你的代码来包含在主线内核中. 
                        头文件&lt;linux/kd.h&gt; 是这个老式方法的例子, 使用 16-位的调整值来定义 ioctl 
                        命令. 那个源代码依靠调整数因为使用那个时候遵循的惯例, 不是由于懒惰. 
                        现在改变它可能导致无理由的不兼容.</P></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=TheReturnValue.sect2></A>6.1.2.&nbsp;返回值</H3></DIV></DIV></DIV>
                        <P>ioctl 的实现常常是一个 switch 语句, 基于命令号. 
                        但是当命令号没有匹配一个有效的操作时缺省的选择应当是什么? 这个问题是有争议的. 几个内核函数返回 
                        -ENIVAL("Invalid argument"), 它有意义是因为命令参数确实不是一个有效的. POSIX 
                        标准, 但是, 说如果一个不合适的 ioctl 命令被发出, 那么 -ENOTTY 应当被返回. 这个错误码被 
                        C 库解释为"设备的不适当的 ioctl", 这常常正是程序员需要听到的. 然而, 它仍然是相当普遍的来返回 
                        -EINVAL, 对于响应一个无效的 ioctl 命令.</P></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=ThePredefinedCommands.sect2></A>6.1.3.&nbsp;预定义的命令</H3></DIV></DIV></DIV>
                        <P>尽管 ioctl 系统调用最常用来作用于设备, 内核能识别几个命令. 注意这些命令, 当用到你的设备时, 
                        在你自己的文件操作被调用之前被解码. 因此, 如果你选择相同的号给一个你的 ioctl命令, 
                        你不会看到任何的给那个命令的请求, 并且应用程序获得某些不期望的东西, 因为在 ioctl 
号之间的冲突.</P>
                        <P>预定义命令分为 3 类:</P>
                        <DIV class=itemizedlist>
                        <UL type=disc>
                          <LI>
                          <P>可对任何文件发出的(常规, 设备, FIFO, 或者 socket) 的那些.</P>
                          <LI>
                          <P>只对常规文件发出的那些.</P>
                          <LI>
                          <P>对文件系统类型特殊的那些.</P></LI></UL></DIV>
                        <P>最后一类的命令由宿主文件系统的实现来执行(这是 chattr 命令如何工作的). 
                        设备驱动编写者只对第一类命令感兴趣, 它们的魔数是 "T". 查看其他类的工作留给读者作为练习; 
                        ext2_ioctl 是最有趣的函数(并且比预期的要容易理解), 因为它实现 append-only 标志和 
                        immutable 标志.</P>
                        <P>下列 ioctl 命令是预定义给任何文件, 包括设备特殊的文件:</P>
                        <DIV class=variablelist>
                        <DL>
                          <DT><SPAN class=term><SPAN>FIOCLEX </SPAN></SPAN>
                          <DD>
                          <P>设置 close-on-exec 标志(File IOctl Close on EXec). 
                          设置这个标志使文件描述符被关闭, 当调用进程执行一个新程序时.</P>
                          <DT><SPAN class=term><SPAN>FIONCLEX </SPAN></SPAN>
                          <DD>
                          <P>清除 close-no-exec 标志(File IOctl Not CLose on EXec). 
                          这个命令恢复普通文件行为, 复原上面 FIOCLEX 所做的. FIOASYNC 
                          为这个文件设置或者复位异步通知(如同在本章中"异步通知"一节中讨论的). 注意直到 Linux 2.2.4 
                          版本的内核不正确地使用这个命令来修改 O_SYNC 标志. 因为两个动作都可通过 fcntl 来完成, 
                          没有人真正使用 FIOASYNC 命令, 它在这里出现只是为了完整性.</P>
                          <DT><SPAN class=term><SPAN>FIOQSIZE </SPAN></SPAN>
                          <DD>
                          <P>这个命令返回一个文件或者目录的大小; 当用作一个设备文件, 但是, 它返回一个 ENOTTY 
                          错误.</P>
                          <DT><SPAN class=term><SPAN>FIONBIO</SPAN></SPAN> 
                          <DD>
                          <P>"File IOctl Non-Blocking I/O"(在"阻塞和非阻塞操作"一节中描述). 
                          这个调用修改在 filp-&gt;f_flags 中的 O_NONBLOCK 标志. 给这个系统调用的第 3 
                          个参数用作指示是否这个标志被置位或者清除. (我们将在本章看到这个标志的角色). 
                          注意常用的改变这个标志的方法是使用 fcntl 系统调用, 使用 F_SETFL 
                        命令.</P></DD></DL></DIV>
                        <P>列表中的最后一项介绍了一个新的系统调用, fcntl, 它看来象 ioctl. 事实上, fcntl 
                        调用非常类似 ioctl, 它也是获得一个命令参数和一个额外的(可选地)参数. 它保持和 ioctl 
                        独立主要是因为历史原因: 当 Unix 开发者面对控制 I/O 操作的问题时, 他们决定文件和设备是不同的. 
                        那时, 有 ioctl 实现的唯一设备是 ttys, 它解释了为什么 -ENOTTY 是标准的对不正确 
                        ioctl 命令的回答. 事情已经改变, 但是 fcntl 保留为一个独立的系统调用.</P></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=UsingtheioctlArgument.sect2></A>6.1.4.&nbsp;使用 
                        ioctl 参数</H3></DIV></DIV></DIV>
                        <P>在看 scull 驱动的 ioctl 代码之前, 我们需要涉及的另一点是如何使用这个额外的参数. 
                        如果它是一个整数, 就容易: 它可以直接使用. 如果它是一个指针, 但是, 必须小心些.</P>
                        <P>当用一个指针引用用户空间, 我们必须确保用户地址是有效的. 
                        试图存取一个没验证过的用户提供的指针可能导致不正确的行为, 一个内核 oops, 系统崩溃, 或者安全问题. 
                        它是驱动的责任来对每个它使用的用户空间地址进行正确的检查, 并且返回一个错误如果它是无效的.</P>
                        <P>在第 3 章, 我们看了 copy_from_user 和 copy_to_user 函数, 
                        它们可用来安全地移动数据到和从用户空间. 这些函数也可用在 ioctl 方法中, 但是 ioctl 
                        调用常常包含小数据项, 可通过其他方法更有效地操作. 开始, 地址校验(不传送数据)由函数 access_ok 
                        实现, 它定义在 &lt;asm/uaccess.h&gt;:</P><PRE class=programlisting>int access_ok(int type, const void *addr, unsigned long size); 
</PRE>
                        <P>第一个参数应当是 VERIFY_READ 或者 VERIFY_WRITE, 
                        依据这个要进行的动作是否是读用户空间内存区或者写它. addr 参数持有一个用户空间地址, size 
                        是一个字节量. 例如, 如果 ioctl 需要从用户空间读一个整数, size 是 sizeof(int). 
                        如果你需要读和写给定地址, 使用 VERIFY_WRITE, 因为它是 VERIRY_READ 的超集.</P>
                        <P>不象大部分的内核函数, access_ok 返回一个布尔值: 1 是成功(存取没问题)和 0 
                        是失败(存取有问题). 如果它返回假, 驱动应当返回 -EFAULT 给调用者.</P>
                        <P>关于 access_ok有多个有趣的东西要注意. 首先, 它不做校验内存存取的完整工作; 
                        它只检查看这个内存引用是在这个进程有合理权限的内存范围中. 特别地, access_ok 
                        确保这个地址不指向内核空间内存. 第2, 大部分驱动代码不需要真正调用 access_ok. 
                        后面描述的内存存取函数为你负责这个. 但是, 我们来演示它的使用, 以便你可见到它如何完成.</P>
                        <P>scull 源码利用了 ioclt 号中的位段来检查参数, 在 switch 之前:</P><PRE class=programlisting>int err = 0, tmp;
int retval = 0;
/*
 * extract the type and number bitfields, and don't decode
 * wrong cmds: return ENOTTY (inappropriate ioctl) before access_ok()
 */
if (_IOC_TYPE(cmd) != SCULL_IOC_MAGIC)
        return -ENOTTY;
if (_IOC_NR(cmd) &gt; SCULL_IOC_MAXNR)
        return -ENOTTY;

/*
 * the direction is a bitmask, and VERIFY_WRITE catches R/W
 * transfers. `Type' is user-oriented, while
 * access_ok is kernel-oriented, so the concept of "read" and
 * "write" is reversed
 */
if (_IOC_DIR(cmd) &amp; _IOC_READ)
        err = !access_ok(VERIFY_WRITE, (void __user *)arg, _IOC_SIZE(cmd));
else if (_IOC_DIR(cmd) &amp; _IOC_WRITE)
        err = !access_ok(VERIFY_READ, (void __user *)arg, _IOC_SIZE(cmd));
if (err)
        return -EFAULT;
</PRE>
                        <P>在调用 access_ok 之后, 驱动可安全地进行真正的传输. 加上 copy_from_user 和 
                        copy_to_user_ 函数, 程序员可利用一组为被最多使用的数据大小(1, 2, 4, 和 8 
                        字节)而优化过的函数. 这些函数在下面列表中描述, 它们定义在 
                        &lt;asm/uaccess.h&gt;:</P>
                        <DIV class=variablelist>
                        <DL>
                          <DT><SPAN class=term><SPAN>put_user(datum, 
                          ptr)</SPAN></SPAN> 
                          <DD>
                          <DT><SPAN class=term><SPAN>__put_user(datum, 
                          ptr)</SPAN></SPAN> 
                          <DD>
                          <P>这些宏定义写 datum 到用户空间; 它们相对快, 并且应当被调用来代替 copy_to_user 
                          无论何时要传送单个值时. 这些宏已被编写来允许传递任何类型的指针到 put_user, 
                          只要它是一个用户空间地址. 传送的数据大小依赖 prt 参数的类型, 并且在编译时使用 sizeof 和 
                          typeof 等编译器内建宏确定. 结果是, 如果 prt 是一个 char 指针, 传送一个字节, 
                          以及对于 2, 4, 和 可能的 8 字节.</P>
                          <P>put_user 检查来确保这个进程能够写入给定的内存地址. 它在成功时返回 0, 并且在错误时返回 
                          -EFAULT. __put_user 进行更少的检查(它不调用 access_ok), 
                          但是仍然能够失败如果被指向的内存对用户是不可写的. 因此, __put_user 应当只用在内存区已经用 
                          access_ok 检查过的时候.</P>
                          <P>作为一个通用的规则, 当你实现一个 read 方法时, 调用 __put_user 来节省几个周期, 
                          或者当你拷贝几个项时, 因此, 在第一次数据传送之前调用 access_ok 一次, 如同上面 ioctl 
                          所示.</P>
                          <DT><SPAN class=term><SPAN>get_user(local, 
                          ptr)</SPAN></SPAN> 
                          <DD>
                          <DT><SPAN class=term><SPAN>__get_user(local, 
                          ptr)</SPAN></SPAN> 
                          <DD>
                          <P>这些宏定义用来从用户空间接收单个数据. 它们象 put_user 和 __put_user, 
                          但是在相反方向传递数据. 获取的值存储于本地变量 local; 返回值指出这个操作是否成功. 再次, 
                          __get_user 应当只用在已经使用 access_ok 
                        校验过的地址.</P></DD></DL></DIV>
                        <P>如果做一个尝试来使用一个列出的函数来传送一个不适合特定大小的值, 结果常常是一个来自编译器的奇怪消息, 
                        例如"coversion to non-scalar type requested". 在这些情况中, 必须使用 
                        copy_to_user 或者 copy_from_user.</P></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=CapabilitiesandRestrictedOperations.sect2></A>6.1.5.&nbsp;兼容性和受限操作</H3></DIV></DIV></DIV>
                        <P>存取一个设备由设备文件上的许可权控制, 并且驱动正常地不涉及到许可权的检查. 但是, 有些情形, 
                        在保证给任何用户对设备的读写许可的地方, 一些控制操作仍然应当被拒绝. 例如, 
                        不是所有的磁带驱动器的用户都应当能够设置它的缺省块大小, 
                        并且一个已经被给予对一个磁盘设备读写权限的用户应当仍然可能被拒绝来格式化它. 在这样的情况下, 
                        驱动必须进行额外的检查来确保用户能够进行被请求的操作.</P>
                        <P>传统上 unix 系统对超级用户帐户限制了特权操作. 这意味着特权是一个全有-或-全无的东西 -- 
                        超级用户可能任意做任何事情, 但是所有其他的用户被高度限制了. Linux 内核提供了一个更加灵活的系统, 
                        称为能力. 一个基于能力的系统丢弃了全有-或全无模式, 并且打破特权操作为独立的子类. 这种方式, 
                        一个特殊的用户(或者是程序)可被授权来进行一个特定的特权操作而不必泄漏进行其他的, 无关的操作的能力. 
                        内核在许可权管理上排他地使用能力, 并且输出 2 个系统调用 capget 和 capset, 
                        来允许它们被从用户空间管理.</P>
                        <P>全部能力可在 &lt;linux/capability.h&gt; 中找到. 这些是对系统唯一可用的能力; 
                        对于驱动作者或者系统管理员, 不可能不修改内核源码而来定义新的. 设备驱动编写者可能感兴趣的这些能力的一个子集, 
                        包括下面:</P>
                        <DIV class=variablelist>
                        <DL>
                          <DT><SPAN class=term>CAP_DAC_OVERRIDE 
                          <SPAN></SPAN></SPAN>
                          <DD>
                          <P>这个能力来推翻在文件和目录上的存取的限制(数据存取控制, 或者 DAC).</P>
                          <DT><SPAN class=term>CAP_NET_ADMIN 
<SPAN></SPAN></SPAN>
                          <DD>
                          <P>进行网络管理任务的能力, 包括那些能够影响网络接口的.</P>
                          <DT><SPAN class=term>CAP_SYS_MODULE 
                          <SPAN></SPAN></SPAN>
                          <DD>
                          <P>加载或去除内核模块的能力.</P>
                          <DT><SPAN class=term>CAP_SYS_RAWIO 
<SPAN></SPAN></SPAN>
                          <DD>
                          <P>进行 "raw" I/O 操作的能力. 例子包括存取设备端口或者直接和 USB 设备通讯.</P>
                          <DT><SPAN class=term>CAP_SYS_ADMIN 
<SPAN></SPAN></SPAN>
                          <DD>
                          <P>一个捕获-全部的能力, 提供对许多系统管理操作的存取.</P>
                          <DT><SPAN class=term>CAP_SYS_TTY_CONFIG 
                          <SPAN></SPAN></SPAN>
                          <DD>
                          <P>进行 tty 配置任务的能力.</P></DD></DL></DIV>
                        <P>在进行一个特权操作之前, 一个设备驱动应当检查调用进程有合适的能力; 
                        不这样做可能导致用户进程进行非法的操作, 对系统的稳定和安全有坏的后果. 能力检查是通过 capable 
                        函数来进行的(定义在 &lt;linux/sched.h&gt;):</P><PRE class=programlisting> int capable(int capability); 
</PRE>
                        <P>在 scull 例子驱动中, 任何用户被许可来查询 quantum 和 quantum 集的大小. 
                        只有特权用户, 但是, 可改变这些值, 因为不适当的值可能很坏地影响系统性能. 当需要时, ioctl 的 
                        scull 实现检查用户的特权级别, 如下:</P><PRE class=programlisting> if (! capable (CAP_SYS_ADMIN))
 return -EPERM;
</PRE>
                        <P>在这个任务缺乏一个更加特定的能力时, CAP_SYS_ADMIN 被选择来做这个测试.</P></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=TheImplementationoftheioctl.sect2></A>6.1.6.&nbsp;ioctl 
                        命令的实现</H3></DIV></DIV></DIV>
                        <P>ioctl 的 scull 实现只传递设备的配置参数, 并且象下面这样容易:</P><PRE class=programlisting>switch(cmd)
{
case SCULL_IOCRESET:
        scull_quantum = SCULL_QUANTUM;
        scull_qset = SCULL_QSET;
        break;

case SCULL_IOCSQUANTUM: /* Set: arg points to the value */
        if (! capable (CAP_SYS_ADMIN))

                return -EPERM;
        retval = __get_user(scull_quantum, (int __user *)arg);
        break;

case SCULL_IOCTQUANTUM: /* Tell: arg is the value */
        if (! capable (CAP_SYS_ADMIN))

                return -EPERM;
        scull_quantum = arg;
        break;

case SCULL_IOCGQUANTUM: /* Get: arg is pointer to result */
        retval = __put_user(scull_quantum, (int __user *)arg);
        break;

case SCULL_IOCQQUANTUM: /* Query: return it (it's positive) */
        return scull_quantum;

case SCULL_IOCXQUANTUM: /* eXchange: use arg as pointer */
        if (! capable (CAP_SYS_ADMIN))

                return -EPERM;
        tmp = scull_quantum;
        retval = __get_user(scull_quantum, (int __user *)arg);
        if (retval == 0)

                retval = __put_user(tmp, (int __user *)arg);
        break;

case SCULL_IOCHQUANTUM: /* sHift: like Tell + Query */
        if (! capable (CAP_SYS_ADMIN))
                return -EPERM;
        tmp = scull_quantum;
        scull_quantum = arg;
        return tmp;

default: /* redundant, as cmd was checked against MAXNR */
        return -ENOTTY;
}
return retval;
</PRE>
                        <P>scull 还包含 6 个入口项作用于 scull_qset. 这些入口项和给 scull_quantum 
                        的是一致的, 并且不值得展示出来.</P>
                        <P>从调用者的观点看(即从用户空间), 这 6 种传递和接收参数的方法看来如下:</P><PRE class=programlisting>int quantum;
ioctl(fd,SCULL_IOCSQUANTUM, &amp;quantum);  /* Set by pointer */
ioctl(fd,SCULL_IOCTQUANTUM, quantum);  /* Set by value */
ioctl(fd,SCULL_IOCGQUANTUM, &amp;quantum);  /* Get by pointer */
quantum = ioctl(fd,SCULL_IOCQQUANTUM);  /* Get by return value */
ioctl(fd,SCULL_IOCXQUANTUM, &amp;quantum);  /* Exchange by pointer */

quantum = ioctl(fd,SCULL_IOCHQUANTUM, quantum); /* Exchange by value */
</PRE>
                        <P>当然, 一个正常的驱动不可能实现这样一个调用模式的混合体. 我们这里这样做只是为了演示做事情的不同方式. 
                        但是, 正常地, 数据交换将一致地进行, 通过指针或者通过值, 并且要避免混合这 2 
种技术.</P></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=DeviceControlWithoutioctl.sect2></A>6.1.7.&nbsp;不用 
                        ioctl 的设备控制</H3></DIV></DIV></DIV>
                        <P>有时控制设备最好是通过写控制序列到设备自身来实现. 例如, 这个技术用在控制台驱动中, 这里所谓的 
                        escape 序列被用来移动光标, 改变缺省的颜色, 或者进行其他的配置任务. 
                        这样实现设备控制的好处是用户可仅仅通过写数据控制设备, 不必使用(或者有时候写)只为配置设备而建立的程序. 
                        当设备可这样来控制, 发出命令的程序甚至常常不需要运行在和它要控制的设备所在的同一个系统上.</P>
                        <P>例如, setterm 程序作用于控制台(或者其他终端)配置, 通过打印 escape 序列. 
                        控制程序可位于和被控制的设备不同的一台计算机上, 因为一个简单的数据流重定向可完成这个配置工作. 
                        这是每次你运行一个远程 tty 会话时所发生的事情: escape 序列在远端被打印但是影响到本地的 tty; 
                        然而, 这个技术不局限于 ttys.</P>
                        <P>通过打印来控制的缺点是它给设备增加了策略限制; 例如, 
                        它仅仅当你确信在正常操作时控制序列不会出现在正被写入设备的数据中. 这对于 ttys 只是部分正确的. 
                        尽管一个文本显示意味着只显示 ASCII 字符, 有时控制字符可潜入正被写入的数据中, 并且可能, 因此, 
                        影响控制台的配置. 例如, 这可能发生在你显示一个二进制文件到屏幕时; 产生的乱码可能包含任何东西, 
                        并且最后你常常在你的控制台上出现错误的字体.</P>
                        <P>通过写来控制是当然的使用方法了, 对于不用传送数据而只是响应命令的设备, 例如遥控设备.</P>
                        <P>例如, 被你们作者当中的一个编写来好玩的驱动, 移动一个 2 轴上的摄像机. 在这个驱动里, 
                        这个"设备"是一对老式步进电机, 它们不能真正读或写. 给一个步进电机"发送数据流"的概念没有任何意义. 
                        在这个情况下, 驱动解释正被写入的数据作为 ASCII 命令并且转换这个请求为脉冲序列, 来操纵步进电机. 
                        这个概念类似于, 有些, 你发给猫的 AT 命令来建立通讯, 主要的不同是和猫通讯的串口必须也传送真正的数据. 
                        直接设备控制的好处是你可以使用 cat 来移动摄像机, 而不必写和编译特殊的代码来发出 ioctl 
调用.</P>
                        <P>当编写面向命令的驱动, 没有理由实现 ioctl 命令. 一个解释器中的额外命令更容易实现并使用.</P>
                        <P>有时, 然而, 你可能选择使用其他的方法:不必转变 write 方法为一个解释器和避免 ioctl, 
                        你可能选择完全避免写并且专门使用 ioctl 命令, 而实现驱动为使用一个特殊的命令行工具来发送这些命令到驱动. 
                        这个方法转移复杂性从内核空间到用户空间, 这里可能更易处理, 并且帮助保持驱动小, 而拒绝使用简单的 cat 
                        或者 echo 命令.</P></DIV></DIV>
                        <DIV class=footnotes><BR>
                        <HR align=left width=100>

                        <DIV class=footnote>
                        <P><SUP>[<A 
                        href="http://www.deansys.com/doc/ldd3/ch06.html#id433758" 
                        name=ftn.id433758><FONT color=#0000ff>20</FONT></A>] 
                        </SUP>但是, 这个文件的维护在后来有些少见了.</P></DIV>
                        <DIV class=footnote>
                        <P><SUP>[<A 
                        href="http://www.deansys.com/doc/ldd3/ch06.html#id433917" 
                        name=ftn.id433917><FONT color=#0000ff>21</FONT></A>] 
                        </SUP>实际上, 所有的当前使用的 libc 实现(包括 uClibc) 仅将 -4095 到 -1 
                        的值当作错误码. 不幸的是, 能够返回大的负数而不是小的, 没有多大用处.</P>
                        <DIV class=sect1 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H2 class=title style="CLEAR: both"><A 
                        name=BlockingIO.sect1></A>6.2.&nbsp;阻塞 
                        I/O</H2></DIV></DIV></DIV>
                        <P>回顾第 3 章, 我们看到如何实现 read 和 write 方法. 在此, 但是, 
                        我们跳过了一个重要的问题:一个驱动当它无法立刻满足请求应当如何响应? 一个对 read 
                        的调用可能当没有数据时到来, 而以后会期待更多的数据. 或者一个进程可能试图写, 
                        但是你的设备没有准备好接受数据, 因为你的输出缓冲满了. 调用进程往往不关心这种问题; 程序员只希望调用 
                        read 或 write 并且使调用返回, 在必要的工作已完成后. 这样, 在这样的情形中, 
                        你的驱动应当(缺省地)阻塞进程, 使它进入睡眠直到请求可继续. </P>
                        <P>本节展示如何使一个进程睡眠并且之后再次唤醒它. 如常, 但是, 我们必须首先解释几个概念.</P>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=IntroductiontoSleeping.sect2></A>6.2.1.&nbsp;睡眠的介绍</H3></DIV></DIV></DIV>
                        <P>对于一个进程"睡眠"意味着什么? 当一个进程被置为睡眠, 
                        它被标识为处于一个特殊的状态并且从调度器的运行队列中去除. 直到发生某些事情改变了那个状态, 
                        这个进程将不被在任何 CPU 上调度, 并且, 因此, 将不会运行. 一个睡着的进程已被搁置到系统的一边, 
                        等待以后发生事件.</P>
                        <P>对于一个 Linux 驱动使一个进程睡眠是一个容易做的事情. 但是, 
                        有几个规则必须记住以安全的方式编码睡眠.</P>
                        <P>这些规则的第一个是: 当你运行在原子上下文时不能睡眠. 我们在第 5 章介绍过原子操作; 
                        一个原子上下文只是一个状态, 这里多个步骤必须在没有任何类型的并发存取的情况下进行. 这意味着, 对于睡眠, 
                        是你的驱动在持有一个自旋锁, seqlock, 或者 RCU 锁时不能睡眠. 如果你已关闭中断你也不能睡眠. 
                        在持有一个旗标时睡眠是合法的, 但是你应当仔细查看这样做的任何代码. 如果代码在持有一个旗标时睡眠, 
                        任何其他的等待这个旗标的线程也睡眠. 因此发生在持有旗标时的任何睡眠应当短暂, 并且你应当说服自己, 
                        由于持有这个旗标, 你不能阻塞这个将最终唤醒你的进程.</P>
                        <P>另一件要记住的事情是, 当你醒来, 你从不知道你的进程离开 CPU 多长时间或者同时已经发生了什么改变. 
                        你也常常不知道是否另一个进程已经睡眠等待同一个事件; 那个进程可能在你之前醒来并且获取了你在等待的资源. 
                        结果是你不能关于你醒后的系统状态做任何的假设, 并且你必须检查来确保你在等待的条件是, 确实, 真的.</P>
                        <P>一个另外的相关的点, 当然, 是你的进程不能睡眠除非确信其他人, 在某处的, 将唤醒它. 
                        做唤醒工作的代码必须也能够找到你的进程来做它的工作. 确保一个唤醒发生, 是深入考虑你的代码和对于每次睡眠, 
                        确切知道什么系列的事件将结束那次睡眠. 使你的进程可能被找到, 真正地, 通过一个称为等待队列的数据结构实现的. 
                        一个等待队列就是它听起来的样子:一个进程列表, 都等待一个特定的事件.</P>
                        <P>在 Linux 中, 一个等待队列由一个"等待队列头"来管理, 一个 wait_queue_head_t 
                        类型的结构, 定义在&lt;linux/wait.h&gt;中. 一个等待队列头可被定义和初始化, 
使用:</P><PRE class=programlisting>DECLARE_WAIT_QUEUE_HEAD(name); 
</PRE>
                        <P>或者动态地, 如下:</P><PRE class=programlisting>wait_queue_head_t my_queue;
init_waitqueue_head(&amp;my_queue);
</PRE>
                        <P>我们将很快返回到等待队列结构, 但是我们知道了足够多的来首先看看睡眠和唤醒.</P></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=SimpleSleeping.sect2></A>6.2.2.&nbsp;简单睡眠</H3></DIV></DIV></DIV>
                        <P>当一个进程睡眠, 它这样做以期望某些条件在以后会成真. 如我们之前注意到的, 
                        任何睡眠的进程必须在它再次醒来时检查来确保它在等待的条件真正为真. Linux 
                        内核中睡眠的最简单方式是一个宏定义, 称为 wait_event(有几个变体); 
                        它结合了处理睡眠的细节和进程在等待的条件的检查. wait_event 的形式是:</P><PRE class=programlisting>wait_event(queue, condition)
wait_event_interruptible(queue, condition)
wait_event_timeout(queue, condition, timeout)
wait_event_interruptible_timeout(queue, condition, timeout)
</PRE>
                        <P>在所有上面的形式中, queue 是要用的等待队列头. 注意它是"通过值"传递的. 
                        条件是一个被这个宏在睡眠前后所求值的任意的布尔表达式; 直到条件求值为真值, 进程继续睡眠. 
                        注意条件可能被任意次地求值, 因此它不应当有任何边界效应.</P>
                        <P>如果你使用 wait_event, 你的进程被置为不可中断地睡眠, 如同我们之前已经提到的, 
                        它常常不是你所要的. 首选的选择是 wait_event_interruptible, 它可能被信号中断. 
                        这个版本返回一个你应当检查的整数值; 一个非零值意味着你的睡眠被某些信号打断, 并且你的驱动可能应当返回 
                        -ERESTARTSYS. 最后的版本(wait_event_timeout 和 
                        wait_event_interruptible_timeout)等待一段有限的时间; 
                        在这个时间期间(以嘀哒数表达的, 我们将在第 7 章讨论)超时后, 这个宏返回一个 0 
                        值而不管条件是如何求值的.</P>
                        <P>图片的另一半, 当然, 是唤醒. 一些其他的执行线程(一个不同的进程, 或者一个中断处理, 
                        也许)必须为你进行唤醒, 因为你的进程, 当然, 是在睡眠. 基本的唤醒睡眠进程的函数称为 wake_up. 
                        它有几个形式(但是我们现在只看其中 2 个):</P><PRE class=programlisting>void wake_up(wait_queue_head_t *queue);
void wake_up_interruptible(wait_queue_head_t *queue);
</PRE>
                        <P>wake_up 唤醒所有的在给定队列上等待的进程(尽管这个情形比那个要复杂一些, 如同我们之后将见到的). 
                        其他的形式(wake_up_interruptible)限制它自己到处理一个可中断的睡眠. 通常, 这 2 
                        个是不用区分的(如果你使用可中断的睡眠); 实际上, 惯例是使用 wake_up 如果你在使用 
                        wait_event , wake_up_interruptible 如果你在使用 
                        wait_event_interruptible.</P>
                        <P>我们现在知道足够多来看一个简单的睡眠和唤醒的例子. 在这个例子代码中, 你可找到一个称为 sleepy 
                        的模块. 它实现一个有简单行为的设备:任何试图从这个设备读取的进程都被置为睡眠. 无论何时一个进程写这个设备, 
                        所有的睡眠进程被唤醒. 这个行为由下面的 read 和 write 方法实现:</P><PRE class=programlisting>static DECLARE_WAIT_QUEUE_HEAD(wq);
static int flag = 0;

ssize_t sleepy_read (struct file *filp, char __user *buf, size_t count, loff_t *pos)
{
        printk(KERN_DEBUG "process %i (%s) going to sleep\n",
               current-&gt;pid, current-&gt;comm);
        wait_event_interruptible(wq, flag != 0);
        flag = 0;
        printk(KERN_DEBUG "awoken %i (%s)\n", current-&gt;pid, current-&gt;comm);
        return 0; /* EOF */
}
ssize_t sleepy_write (struct file *filp, const char __user *buf, size_t count, loff_t *pos)
{
        printk(KERN_DEBUG "process %i (%s) awakening the readers...\n",
               current-&gt;pid, current-&gt;comm);
        flag = 1;
        wake_up_interruptible(&amp;wq);
        return count; /* succeed, to avoid retrial */

}
</PRE>
                        <P>注意这个例子里 flag 变量的使用. 因为 wait_event_interruptible 
                        检查一个必须变为真的条件, 我们使用 flag 来创建那个条件.</P>
                        <P>有趣的是考虑当 sleepy_write 被调用时如果有 2 个进程在等待会发生什么. 因为 
                        sleepy_read 重置 flag 为 0 一旦它醒来, 你可能认为醒来的第 2 个进程会立刻回到睡眠. 
                        在一个单处理器系统, 这几乎一直是发生的事情. 但是重要的是要理解为什么你不能依赖这个行为. 
                        wake_up_interruptible 调用将使 2 个睡眠进程醒来. 完全可能它们都注意到 flag 
                        是非零, 在另一个有机会重置它之前. 对于这个小模块, 这个竞争条件是不重要的. 在一个真实的驱动中, 
                        这种竞争可能导致少见的难于查找的崩溃. 如果正确的操作要求只能有一个进程看到这个非零值, 
                        它将必须以原子的方式被测试. 我们将见到一个真正的驱动如何处理这样的情况. 
                        但首先我们必须开始另一个主题.</P></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=BlockingandNonblockingOperations.sect2></A>6.2.3.&nbsp;阻塞和非阻塞操作 
                        </H3></DIV></DIV></DIV>
                        <P>在我们看全功能的 read 和 write 方法的实现之前, 我们触及的最后一点是决定何时使进程睡眠. 
                        有时实现正确的 unix 语义要求一个操作不阻塞, 即便它不能完全地进行下去.</P>
                        <P>有时还有调用进程通知你他不想阻塞, 不管它的 I/O 是否继续. 明确的非阻塞 I/O 由 
                        filp-&gt;f_flags 中的 O_NONBLOCK 标志来指示. 这个标志定义于 
                        &lt;linux/fcntl.h&gt;, 被 &lt;linux/fs.h&gt;自动包含. 
                        这个标志得名自"打开-非阻塞", 因为它可在打开时指定(并且起初只能在那里指定). 如果你浏览源码, 
                        你会发现一些对一个 O_NDELAY 标志的引用; 这是一个替代 O_NONBLOCK 的名子, 为兼容 
                        System V 代码而被接受的. 这个标志缺省地被清除, 因为一个等待数据的进程的正常行为仅仅是睡眠. 
                        在一个阻塞操作的情况下, 这是缺省地, 下列的行为应当实现来符合标准语法:</P>
                        <DIV class=itemizedlist>
                        <UL type=disc>
                          <LI>
                          <P>如果一个进程调用 read 但是没有数据可用(尚未), 这个进程必须阻塞. 
                          这个进程在有数据达到时被立刻唤醒, 并且那个数据被返回给调用者, 即便小于在给方法的 count 
                          参数中请求的数量.</P>
                          <LI>
                          <P>如果一个进程调用 write 并且在缓冲中没有空间, 这个进程必须阻塞, 并且它必须在一个与用作 
                          read 的不同的等待队列中. 当一些数据被写入硬件设备, 并且在输出缓冲中的空间变空闲, 
                          这个进程被唤醒并且写调用成功, 尽管数据可能只被部分写入如果在缓冲只没有空间给被请求的 count 
                          字节.</P></LI></UL></DIV>
                        <P>这 2 句都假定有输入和输出缓冲; 实际上, 几乎每个设备驱动都有. 
                        要求有输入缓冲是为了避免丢失到达的数据, 当无人在读时. 相反, 数据在写时不能丢失, 
                        因为如果系统调用不能接收数据字节, 它们保留在用户空间缓冲. 即便如此, 输出缓冲几乎一直有用, 
                        对于从硬件挤出更多的性能.</P>
                        <P>在驱动中实现输出缓冲所获得的性能来自减少了上下文切换和用户级/内核级切换的次数. 
                        没有一个输出缓冲(假定一个慢速设备), 每次系统调用接收这样一个或几个字符, 并且当一个进程在 write 
                        中睡眠, 另一个进程运行(那是一次上下文切换). 当第一个进程被唤醒, 它恢复(另一次上下文切换), 
                        写返回(内核/用户转换), 并且这个进程重新发出系统调用来写入更多的数据(用户/内核转换); 
                        这个调用阻塞并且循环继续. 增加一个输出缓冲可允许驱动在每个写调用中接收大的数据块, 性能上有相应的提高. 
                        如果这个缓冲足够大, 写调用在第一次尝试就成功 -- 被缓冲的数据之后将被推到设备 -- 
                        不必控制需要返回用户空间来第二次或者第三次写调用. 选择一个合适的值给输出缓冲显然是设备特定的.</P>
                        <P>我们不使用一个输入缓冲在 scull中, 因为数据当发出 read 时已经可用. 类似的, 不用输出缓冲, 
                        因为数据被简单地拷贝到和设备关联的内存区. 本质上, 这个设备是一个缓冲, 因此额外缓冲的实现可能是多余的. 
                        我们将在第 10 章见到缓冲的使用.</P>
                        <P>如果指定 O_NONBLOCK, read 和 write 的行为是不同的. 在这个情况下, 
                        这个调用简单地返回 -EAGAIN(("try it agin")如果一个进程当没有数据可用时调用 read , 
                        或者如果当缓冲中没有空间时它调用 write .</P>
                        <P>如你可能期望的, 非阻塞操作立刻返回, 允许这个应用程序轮询数据. 应用程序当使用 stdio 
                        函数处理非阻塞文件中, 必须小心, 因为它们容易搞错一个的非阻塞返回为 EOF. 它们始终必须检查 
                        errno.</P>
                        <P>自然地, O_NONBLOCK 也在 open 方法中有意义. 这个发生在当这个调用真正阻塞长时间时; 
                        例如, 当打开(为读存取)一个 没有写者的(尚无)FIFO, 或者存取一个磁盘文件使用一个悬挂锁. 常常地, 
                        打开一个设备或者成功或者失败, 没有必要等待外部的事件. 有时, 但是, 打开这个设备需要一个长的初始化, 
                        并且你可能选择在你的 open 方法中支持 O_NONBLOCK , 通过立刻返回 
                        -EAGAIN,如果这个标志被设置. 在开始这个设备的初始化进程之后. 这个驱动可能还实现一个阻塞 open 
                        来支持存取策略, 通过类似于文件锁的方式. 我们将见到这样一个实现在"阻塞 open 作为对 EBUSY 
                        的替代"一节, 在本章后面.</P>
                        <P>一些驱动可能还实现特别的语义给 O_NONBLOCK; 例如, 一个磁带设备的 open 
                        常常阻塞直到插入一个磁带. 如果这个磁带驱动器使用 O_NONBLOCK 打开, 这个 open 立刻成功, 
                        不管是否介质在或不在.</P>
                        <P>只有 read, write, 和 open 文件操作受到非阻塞标志影响.</P></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=ABlockingIOExample.sect2></A>6.2.4.&nbsp;一个阻塞 I/O 
                        的例子</H3></DIV></DIV></DIV>
                        <P>最后, 我们看一个实现了阻塞 I/O 的真实驱动方法的例子. 这个例子来自 scullpipe 驱动; 
                        它是 scull 的一个特殊形式, 实现了一个象管道的设备.</P>
                        <P>在驱动中, 一个阻塞在读调用上的进程被唤醒, 当数据到达时; 常常地硬件发出一个中断来指示这样一个事件, 
                        并且驱动唤醒等待的进程作为处理这个中断的一部分. scullpipe 驱动不同, 
                        以至于它可运行而不需要任何特殊的硬件或者一个中断处理. 我们选择来使用另一个进程来产生数据并唤醒读进程; 
                        类似地, 读进程被用来唤醒正在等待缓冲空间可用的写者进程.</P>
                        <P>这个设备驱动使用一个设备结构, 它包含 2 个等待队列和一个缓冲. 
                        缓冲大小是以常用的方法可配置的(在编译时间, 加载时间, 或者运行时间).</P><PRE class=programlisting>struct scull_pipe
{
        wait_queue_head_t inq, outq; /* read and write queues */
        char *buffer, *end; /* begin of buf, end of buf */
        int buffersize; /* used in pointer arithmetic */
        char *rp, *wp; /* where to read, where to write */
        int nreaders, nwriters; /* number of openings for r/w */
        struct fasync_struct *async_queue; /* asynchronous readers */
        struct semaphore sem;  /* mutual exclusion semaphore */
        struct cdev cdev;  /* Char device structure */
};
</PRE>
                        <P>读实现既管理阻塞也管理非阻塞输入, 看来如此:</P><PRE class=programlisting>static ssize_t scull_p_read (struct file *filp, char __user *buf, size_t count, loff_t *f_pos)
{
        struct scull_pipe *dev = filp-&gt;private_data;
        if (down_interruptible(&amp;dev-&gt;sem))
                return -ERESTARTSYS;

        while (dev-&gt;rp == dev-&gt;wp)
        { /* nothing to read */
                up(&amp;dev-&gt;sem); /* release the lock */
                if (filp-&gt;f_flags &amp; O_NONBLOCK)

                        return -EAGAIN;
                PDEBUG("\"%s\" reading: going to sleep\n", current-&gt;comm);
                if (wait_event_interruptible(dev-&gt;inq, (dev-&gt;rp != dev-&gt;wp)))
                        return -ERESTARTSYS; /* signal: tell the fs layer to handle it */ /* otherwise loop, but first reacquire the lock */
                if (down_interruptible(&amp;dev-&gt;sem))
                        return -ERESTARTSYS;
        }
        /* ok, data is there, return something */

        if (dev-&gt;wp &gt; dev-&gt;rp)
                count = min(count, (size_t)(dev-&gt;wp - dev-&gt;rp));
        else /* the write pointer has wrapped, return data up to dev-&gt;end */
                count = min(count, (size_t)(dev-&gt;end - dev-&gt;rp));
        if (copy_to_user(buf, dev-&gt;rp, count))
        {
                up (&amp;dev-&gt;sem);
                return -EFAULT;
        }
        dev-&gt;rp += count;
        if (dev-&gt;rp == dev-&gt;end)

                dev-&gt;rp = dev-&gt;buffer; /* wrapped */
        up (&amp;dev-&gt;sem);

        /* finally, awake any writers and return */
        wake_up_interruptible(&amp;dev-&gt;outq);
        PDEBUG("\"%s\" did read %li bytes\n",current-&gt;comm, (long)count);
        return count;
}
</PRE>
                        <P>如同你可见的, 我们在代码中留有一些 PDEBUG 语句. 当你编译这个驱动, 
                        你可使能消息机制来易于跟随不同进程间的交互.</P>
                        <P>让我们仔细看看 scull_p_read 如何处理对数据的等待. 这个 while 
                        循环在持有设备旗标下测试这个缓冲. 如果有数据在那里, 我们知道我们可立刻返回给用户, 不必睡眠, 
                        因此整个循环被跳过. 相反, 如果这个缓冲是空的, 我们必须睡眠. 但是在我们可做这个之前, 
                        我们必须丢掉设备旗标; 如果我们要持有它而睡眠, 就不会有写者有机会唤醒我们. 一旦这个确保被丢掉, 
                        我们做一个快速检查来看是否用户已请求非阻塞 I/O, 并且如果是这样就返回. 否则, 是时间调用 
                        wait_event_interruptible.</P>
                        <P>一旦我们过了这个调用, 某些东东已经唤醒了我们, 但是我们不知道是什么. 一个可能是进程接收到了一个信号. 
                        包含 wait_event_interruptible 调用的这个 if 语句检查这种情况. 
                        这个语句保证了正确的和被期望的对信号的反应, 它可能负责唤醒这个进程(因为我们处于一个可中断的睡眠). 
                        如果一个信号已经到达并且它没有被这个进程阻塞, 正确的做法是让内核的上层处理这个事件. 到此, 这个驱动返回 
                        -ERESTARTSYS 到调用者; 这个值被虚拟文件系统(VFS)在内部使用, 它或者重启系统调用或者返回 
                        -EINTR 给用户空间. 我们使用相同类型的检查来处理信号, 给每个读和写实现.</P>
                        <P>但是, 即便没有一个信号, 我们还是不确切知道有数据在那里为获取. 其他人也可能已经在等待数据, 
                        并且它们可能赢得竞争并且首先得到数据. 因此我们必须再次获取设备旗标; 只有这时我们才可以测试读缓冲(在 
                        while 循环中)并且真正知道我们可以返回缓冲中的数据给用户. 全部这个代码的最终结果是, 当我们从 
                        while 循环中退出时, 我们知道旗标被获得并且缓冲中有数据我们可以用.</P>
                        <P>仅仅为了完整, 我们要注意, scull_p_read 可以在另一个地方睡眠, 在我们获得设备旗标之后: 
                        对 copy_to_user 的调用. 如果 scull 当在内核和用户空间之间拷贝数据时睡眠, 
                        它在持有设备旗标中睡眠. 
                        在这种情况下持有旗标是合理的因为它不能死锁系统(我们知道内核将进行拷贝到用户空间并且在不加锁进程中的同一个旗标下唤醒我们), 
                        并且因为重要的是设备内存数组在驱动睡眠时不改变.</P></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=AdvancedSleeping.sect2></A>6.2.5.&nbsp;高级睡眠</H3></DIV></DIV></DIV>
                        <P>许多驱动能够满足它们的睡眠要求, 使用至今我们已涉及到的函数. 但是, 有时需要深入理解 Linux 
                        等待队列机制如何工作. 复杂的加锁或者性能需要可强制一个驱动来使用低层函数来影响一个睡眠. 在本节, 
                        我们在低层看而理解在一个进程睡眠时发生了什么.</P>
                        <DIV class=sect3 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H4 class=title><A 
                        name=Howaprocesssleeps.sect3></A>6.2.5.1.&nbsp;一个进程如何睡眠</H4></DIV></DIV></DIV>
                        <P>如果我们深入 &lt;linux/wait.h&gt;, 你见到在 wait_queue_head_t 
                        类型后面的数据结构是非常简单的; 它包含一个自旋锁和一个链表. 这个链表是一个等待队列入口, 它被声明做 
                        wait_queue_t. 这个结构包含关于睡眠进程的信息和它想怎样被唤醒.</P>
                        <P>使一个进程睡眠的第一步常常是分配和初始化一个 wait_queue_t 结构, 
                        随后将其添加到正确的等待队列. 当所有东西都就位了, 负责唤醒工作的人就可以找到正确的进程.</P>
                        <P>下一步是设置进程的状态来标志它为睡眠. 在 &lt;linux/sched.h&gt; 
                        中定义有几个任务状态. TASK_RUNNING 意思是进程能够运行, 尽管不必在任何特定的时刻在处理器上运行. 
                        有 2 个状态指示一个进程是在睡眠: TASK_INTERRUPTIBLE 和 
                        TASK_UNTINTERRUPTIBLE; 当然, 它们对应 2 类的睡眠. 
                        其他的状态正常地和驱动编写者无关.</P>
                        <P>在 2.6 内核, 对于驱动代码通常不需要直接操作进程状态. 但是, 如果你需要这样做, 
                        使用的代码是:</P><PRE class=programlisting>void set_current_state(int new_state); 
</PRE>
                        <P>在老的代码中, 你常常见到如此的东西:</P><PRE class=programlisting>current-&gt;state = TASK_INTERRUPTIBLE; 
</PRE>
                        <P>但是象这样直接改变 current 是不鼓励的; 当数据结构改变时这样的代码会轻易地失效. 但是, 
                        上面的代码确实展示了自己改变一个进程的当前状态不能使其睡眠. 通过改变 current 状态, 
                        你已改变了调度器对待进程的方式, 但是你还未让出处理器.</P>
                        <P>放弃处理器是最后一步, 但是要首先做一件事: 你必须先检查你在睡眠的条件. 
                        做这个检查失败会引入一个竞争条件; 如果在你忙于上面的这个过程并且有其他的线程刚刚试图唤醒你, 
                        如果这个条件变为真会发生什么? 你可能错过唤醒并且睡眠超过你预想的时间. 因此, 在睡眠的代码下面, 
                        典型地你会见到下面的代码:</P><PRE class=programlisting>if (!condition)
    schedule();
</PRE>
                        <P>通过在设置了进程状态后检查我们的条件, 我们涵盖了所有的可能的事件进展. 
                        如果我们在等待的条件已经在设置进程状态之前到来, 我们在这个检查中注意到并且不真正地睡眠. 如果之后发生了唤醒, 
                        进程被置为可运行的不管是否我们已真正进入睡眠.</P>
                        <P>调用 schedule , 当然, 是引用调度器和让出 CPU 的方式. 无论何时你调用这个函数, 
                        你是在告诉内核来考虑应当运行哪个进程并且转换控制到那个进程, 如果必要. 因此你从不知道在 schedule 
                        返回到你的代码会是多长时间.</P>
                        <P>在 if 测试和可能的调用 schedule (并从其返回)之后, 有些清理工作要做. 
                        因为这个代码不再想睡眠, 它必须保证任务状态被重置为 TASK_RUNNING. 如果代码只是从 
                        schedule 返回, 这一步是不必要的; 那个函数不会返回直到进程处于可运行态. 如果由于不再需要睡眠而对 
                        schedule 的调用被跳过, 进程状态将不正确. 还有必要从等待队列中去除这个进程, 
                        否则它可能被多次唤醒.</P></DIV>
                        <DIV class=sect3 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H4 class=title><A 
                        name=Manualsleeps.sect3></A>6.2.5.2.&nbsp;手动睡眠</H4></DIV></DIV></DIV>
                        <P>在 Linux 内核的之前的版本, 正式的睡眠要求程序员手动处理所有上面的步骤. 它是一个繁琐的过程, 
                        包含相当多的易出错的样板式的代码. 程序员如果愿意还是可能用那种方式手动睡眠; 
                        &lt;linux/sched.h&gt; 包含了所有需要的定义, 以及围绕例子的内核源码. 但是, 
                        有一个更容易的方式.</P>
                        <P>第一步是创建和初始化一个等待队列. 这常常由这个宏定义完成:</P><PRE class=programlisting>DEFINE_WAIT(my_wait); 
</PRE>
                        <P>其中, name 是等待队列入口项的名子. 你可用 2 步来做:</P><PRE class=programlisting>wait_queue_t my_wait;
init_wait(&amp;my_wait);
</PRE>
                        <P>但是常常更容易的做法是放一个 DEFINE_WAIT 行在循环的顶部, 来实现你的睡眠.</P>
                        <P>下一步是添加你的等待队列入口到队列, 并且设置进程状态. 2 个任务都由这个函数处理:</P><PRE class=programlisting>void prepare_to_wait(wait_queue_head_t *queue, wait_queue_t *wait, int state); 
</PRE>
                        <P>这里, queue 和 wait 分别地是等待队列头和进程入口. state 是进程的新状态; 
                        它应当或者是 TASK_INTERRUPTIBLE(给可中断的睡眠, 这常常是你所要的)或者 
                        TASK_UNINTERRUPTIBLE(给不可中断睡眠).</P>
                        <P>在调用 prepare_to_wait 之后, 进程可调用 schedule -- 
                        在它已检查确认它仍然需要等待之后. 一旦 schedule 返回, 就到了清理时间. 这个任务, 也, 
                        被一个特殊的函数处理:</P><PRE class=programlisting>void finish_wait(wait_queue_head_t *queue, wait_queue_t *wait); 
</PRE>
                        <P>之后, 你的代码可测试它的状态并且看是否它需要再次等待.</P>
                        <P>我们早该需要一个例子了. 之前我们看了 给 scullpipe 的 read 方法, 它使用 
                        wait_event. 同一个驱动中的 write 方法使用 prepare_to_wait 和 
                        finish_wait 来实现它的等待. 正常地, 你不会在一个驱动中象这样混用各种方法, 
                        但是我们这样作是为了能够展示 2 种处理睡眠的方式.</P>
                        <P>为完整起见, 首先, 我们看 write 方法本身:</P><PRE class=programlisting>/* How much space is free? */
static int spacefree(struct scull_pipe *dev)
{

        if (dev-&gt;rp == dev-&gt;wp)
                return dev-&gt;buffersize - 1;
        return ((dev-&gt;rp + dev-&gt;buffersize - dev-&gt;wp) % dev-&gt;buffersize) - 1;
}

static ssize_t scull_p_write(struct file *filp, const char __user *buf, size_t count,
                             loff_t *f_pos)
{

        struct scull_pipe *dev = filp-&gt;private_data;
        int result;
        if (down_interruptible(&amp;dev-&gt;sem))
                return -ERESTARTSYS;

        /* Make sure there's space to write */
        result = scull_getwritespace(dev, filp);
        if (result)
                return result; /* scull_getwritespace called up(&amp;dev-&gt;sem) */
        /* ok, space is there, accept something */
        count = min(count, (size_t)spacefree(dev));
        if (dev-&gt;wp &gt;= dev-&gt;rp)
                count = min(count, (size_t)(dev-&gt;end - dev-&gt;wp)); /* to end-of-buf */
        else /* the write pointer has wrapped, fill up to rp-1 */
                count = min(count, (size_t)(dev-&gt;rp - dev-&gt;wp - 1));
        PDEBUG("Going to accept %li bytes to %p from %p\n", (long)count, dev-&gt;wp, buf);
        if (copy_from_user(dev-&gt;wp, buf, count))
        {
                up (&amp;dev-&gt;sem);
                return -EFAULT;
        }
        dev-&gt;wp += count;
        if (dev-&gt;wp == dev-&gt;end)
                dev-&gt;wp = dev-&gt;buffer; /* wrapped */
        up(&amp;dev-&gt;sem);

        /* finally, awake any reader */
        wake_up_interruptible(&amp;dev-&gt;inq); /* blocked in read() and select() */

        /* and signal asynchronous readers, explained late in chapter 5 */
        if (dev-&gt;async_queue)
                kill_fasync(&amp;dev-&gt;async_queue, SIGIO, POLL_IN);
        PDEBUG("\"%s\" did write %li bytes\n",current-&gt;comm, (long)count);
        return count;
}
</PRE>
                        <P>这个代码看来和 read 方法类似, 除了我们已经将睡眠代码放到了一个单独的函数, 称为 
                        scull_getwritespace. 它的工作是确保在缓冲中有空间给新的数据, 睡眠直到有空间可用. 
                        一旦空间在, scull_p_write 可简单地拷贝用户的数据到那里, 调整指针, 
                        并且唤醒可能已经在等待读取数据的进程.</P>
                        <P>处理实际的睡眠的代码是:</P><PRE class=programlisting>/* Wait for space for writing; caller must hold device semaphore. On
 * error the semaphore will be released before returning. */
static int scull_getwritespace(struct scull_pipe *dev, struct file *filp)
{

        while (spacefree(dev) == 0)
        { /* full */
                DEFINE_WAIT(wait);

                up(&amp;dev-&gt;sem);
                if (filp-&gt;f_flags &amp; O_NONBLOCK)
                        return -EAGAIN;

                PDEBUG("\"%s\" writing: going to sleep\n",current-&gt;comm);
                prepare_to_wait(&amp;dev-&gt;outq, &amp;wait, TASK_INTERRUPTIBLE);
                if (spacefree(dev) == 0)
                        schedule();
                finish_wait(&amp;dev-&gt;outq, &amp;wait);
                if (signal_pending(current))

                        return -ERESTARTSYS; /* signal: tell the fs layer to handle it */
                if (down_interruptible(&amp;dev-&gt;sem))
                        return -ERESTARTSYS;
        }
        return 0;

}
</PRE>
                        <P>再次注意 while 循环. 如果有空间可用而不必睡眠, 这个函数简单地返回. 否则, 
                        它必须丢掉设备旗标并且等待. 这个代码使用 DEFINE_WAIT 来设置一个等待队列入口并且 
                        prepare_to_wait 来准备好实际的睡眠. 接着是对缓冲的必要的检查; 
                        我们必须处理的情况是在我们已经进入 while 循环后以及在我们将自己放入等待队列之前 (并且丢弃了旗标), 
                        缓冲中有空间可用了. 没有这个检查, 如果读进程能够在那时完全清空缓冲, 
                        我们可能错过我们能得到的唯一的唤醒并且永远睡眠. 在说服我们自己必须睡眠之后, 我们调用 schedule. 
                        </P>
                        <P>值得再看看这个情况: 当睡眠发生在 if 语句测试和调用 schedule 之间, 会发生什么? 
                        在这个情况里, 都好. 这个唤醒重置了进程状态为 TASK_RUNNING 并且 schedule 返回 -- 
                        尽管不必马上. 只要这个测试发生在进程放置自己到等待队列和改变它的状态之后, 事情都会顺利.</P>
                        <P>为了结束, 我们调用 finish_wait. 对 signal_pending 
                        的调用告诉我们是否我们被一个信号唤醒; 如果是, 我们需要返回到用户并且使它们稍后再试. 否则, 我们请求旗标, 
                        并且再次照常测试空闲空间.</P></DIV>
                        <DIV class=sect3 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H4 class=title><A 
                        name=Exclusivewaits.sect3></A>6.2.5.3.&nbsp;互斥等待</H4></DIV></DIV></DIV>
                        <P>我们已经见到当一个进程调用 wake_up 在等待队列上, 所有的在这个队列上等待的进程被置为可运行的. 
                        在许多情况下, 这是正确的做法. 但是, 在别的情况下, 可能提前知道只有一个被唤醒的进程将成功获得需要的资源, 
                        并且其余的将简单地再次睡眠. 每个这样的进程, 但是, 必须获得处理器, 竞争资源(和任何的管理用的锁), 
                        并且明确地回到睡眠. 如果在等待队列中的进程数目大, 这个"惊群"行为可能严重降低系统的性能.</P>
                        <P>为应对实际世界中的惊群问题, 内核开发者增加了一个"互斥等待"选项到内核中. 
                        一个互斥等待的行为非常象一个正常的睡眠, 有 2 个重要的不同:</P>
                        <DIV class=itemizedlist>
                        <UL type=disc>
                          <LI>
                          <P>当一个等待队列入口有 WQ_FLAG_EXCLUSEVE 标志置位, 它被添加到等待队列的尾部. 
                          没有这个标志的入口项, 相反, 添加到开始.</P>
                          <LI>
                          <P>当 wake_up 被在一个等待队列上调用, 它在唤醒第一个有 WQ_FLAG_EXCLUSIVE 
                          标志的进程后停止.</P></LI></UL></DIV>
                        <P>最后的结果是进行互斥等待的进程被一次唤醒一个, 以顺序的方式, 并且没有引起惊群问题. 
                        但内核仍然每次唤醒所有的非互斥等待者.</P>
                        <P>在驱动中采用互斥等待是要考虑的, 如果满足 2 个条件: 你希望对资源的有效竞争, 
                        并且唤醒一个进程就足够来完全消耗资源当资源可用时. 互斥等待对 Apacheweb 服务器工作地很好, 例如; 
                        当一个新连接进入, 确实地系统中的一个 Apache 进程应当被唤醒来处理它. 我们在 scullpipe 
                        驱动中不使用互斥等待, 但是; 很少见到竞争数据的读者(或者竞争缓冲空间的写者), 并且我们无法知道一个读者, 
                        一旦被唤醒, 将消耗所有的可用数据. </P>
                        <P>使一个进程进入可中断的等待, 是调用 prepare_to_wait_exclusive 
                        的简单事情:</P><PRE class=programlisting>void prepare_to_wait_exclusive(wait_queue_head_t *queue, wait_queue_t *wait, int state); 
</PRE>
                        <P>这个调用, 当用来代替 prepare_to_wait, 
                        设置"互斥"标志在等待队列入口项并且添加这个进程到等待队列的尾部. 注意没有办法使用 wait_event 
                        和它的变体来进行互斥等待.</P></DIV>
                        <DIV class=sect3 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H4 class=title><A 
                        name=Thedetailsofwakingup.sect3></A>6.2.5.4.&nbsp;唤醒的细节</H4></DIV></DIV></DIV>
                        <P>我们已展现的唤醒进程的样子比内核中真正发生的要简单. 
                        当进程被唤醒时产生的真正动作是被位于等待队列入口项的一个函数控制的. 缺省的唤醒函数<SUP>[<A 
                        href="http://www.deansys.com/doc/ldd3/ch06s02.html#ftn.id436200" 
                        name=id436200><FONT 
                        color=#0000ff>22</FONT></A>]</SUP>设置进程为可运行的状态, 
                        并且可能地进行一个上下文切换到有更高优先级进程. 设备驱动应当从不需要提供一个不同的唤醒函数; 如果你例外, 
                        关于如何做的信息见 &lt;linux/wait.h&gt; </P>
                        <P>我们尚未看到所有的 wake_up 变体. 大部分驱动编写者从不需要其他的, 但是, 为完整起见, 
                        这里是整个集合:</P>
                        <DIV class=variablelist>
                        <DL>
                          <DT><SPAN class=term><SPAN>wake_up(wait_queue_head_t 
                          *queue);</SPAN></SPAN> 
                          <DD>
                          <DT><SPAN 
                          class=term><SPAN>wake_up_interruptible(wait_queue_head_t 
                          *queue);</SPAN></SPAN> 
                          <DD>
                          <P>wake_up 唤醒队列中的每个不是在互斥等待中的进程, 并且就只一个互斥等待者, 如果它存在. 
                          wake_up_interruptible 同样, 除了它跳过处于不可中断睡眠的进程. 这些函数, 
                          在返回之前, 使一个或多个进程被唤醒来被调度(尽管如果它们被从一个原子上下文调用, 这就不会发生).</P>
                          <DT><SPAN 
                          class=term><SPAN>wake_up_nr(wait_queue_head_t *queue, 
                          int nr);</SPAN></SPAN> 
                          <DD>
                          <DT><SPAN 
                          class=term><SPAN>wake_up_interruptible_nr(wait_queue_head_t 
                          *queue, int nr);</SPAN></SPAN> 
                          <DD>
                          <P>这些函数类似 wake_up, 除了它们能够唤醒多达 nr 个互斥等待者, 而不只是一个. 注意传递 
                          0 被解释为请求所有的互斥等待者都被唤醒, 而不是一个没有.</P>
                          <DT><SPAN 
                          class=term><SPAN>wake_up_all(wait_queue_head_t 
                          *queue);</SPAN></SPAN> 
                          <DD>
                          <DT><SPAN 
                          class=term><SPAN>wake_up_interruptible_all(wait_queue_head_t 
                          *queue);</SPAN></SPAN> 
                          <DD>
                          <P>这种 wake_up 唤醒所有的进程, 
                          不管它们是否进行互斥等待(尽管可中断的类型仍然跳过在做不可中断等待的进程)</P>
                          <DT><SPAN 
                          class=term><SPAN>wake_up_interruptible_sync(wait_queue_head_t 
                          *queue);</SPAN></SPAN> 
                          <DD>
                          <P>正常地, 一个被唤醒的进程可能抢占当前进程, 并且在 wake_up 返回之前被调度到处理器. 
                          换句话说, 调用 wake_up 可能不是原子的. 如果调用 wake_up 
                          的进程运行在原子上下文(它可能持有一个自旋锁, 例如, 或者是一个中断处理), 这个重调度不会发生. 
                          正常地, 那个保护是足够的. 但是, 如果你需要明确要求不要被调度出处理器在那时, 你可以使用 
                          wake_up_interruptible 的"同步"变体. 这个函数最常用在当调用者要无论如何重新调度, 
                          并且它会更有效的来首先简单地完成剩下的任何小的工作.</P></DD></DL></DIV>
                        <P>如果上面的全部内容在第一次阅读时没有完全清楚, 不必担心. 很少请求会需要调用 
                        wake_up_interruptible 之外的.</P></DIV>
                        <DIV class=sect3 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H4 class=title><A 
                        name=Ancienthistorysleepon.sect3></A>6.2.5.5.&nbsp;以前的历史: 
                        sleep_on</H4></DIV></DIV></DIV>
                        <P>如果你花些时间深入内核源码, 你可能遇到我们到目前忽略讨论的 2 个函数:</P><PRE class=programlisting>void sleep_on(wait_queue_head_t *queue);
void interruptible_sleep_on(wait_queue_head_t *queue);
</PRE>
                        <P>如你可能期望的, 这些函数无条件地使当前进程睡眠在给定队列尚. 这些函数强烈不推荐, 但是, 
                        并且你应当从不使用它们. 如果你想想它则问题是明显的: sleep_on 没提供方法来避免竞争条件. 
                        常常有一个窗口在当你的代码决定它必须睡眠时和当 sleep_on 真正影响到睡眠时. 
                        在那个窗口期间到达的唤醒被错过. 因此, 调用 sleep_on 的代码从不是完全安全的.</P>
                        <P>当前计划对 sleep_on 和 
                        它的变体的调用(有多个我们尚未展示的超时的类型)在不太远的将来从内核中去掉.</P></DIV></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=TestingtheScullpipeDriver.sect2></A>6.2.6.&nbsp;测试 
                        scullpipe 驱动</H3></DIV></DIV></DIV>
                        <P>我们已经见到了 scullpipe 驱动如何实现阻塞 I/O. 如果你想试一试, 
                        这个驱动的源码可在剩下的本书例子中找到. 阻塞 I/O 的动作可通过打开 2 个窗口见到. 
                        第一个可运行一个命令诸如 cat /dev/scullpipe. 如果你接着, 在另一个窗口拷贝文件到 
                        /dev/scullpipe, 你可见到文件的内容出现在第一个窗口.</P>
                        <P>测试非阻塞的动作是技巧性的, 因为可用于 shell 的传统的程序不做非阻塞操作. misc-progs 
                        源码目录包含下面简单的程序, 称为 nbtest, 来测试非阻塞操作. 所有它做的是拷贝它的输入到它的输出, 
                        使用非阻塞 I/O 和在重试间延时. 延时时间在命令行被传递被缺省是 1 秒.</P><PRE class=programlisting>int main(int argc, char **argv)
{

        int delay = 1, n, m = 0;
        if (argc &gt; 1)
                delay=atoi(argv[1]);
        fcntl(0, F_SETFL, fcntl(0,F_GETFL) | O_NONBLOCK); /* stdin */
        fcntl(1, F_SETFL, fcntl(1,F_GETFL) | O_NONBLOCK); /* stdout */

        while (1) {
                n = read(0, buffer, 4096);
                if (n &gt;= 0)
                        m = write(1, buffer, n);
                if ((n &lt; 0 || m &lt; 0) &amp;&amp; (errno != EAGAIN))
                        break;
                sleep(delay);
        }
        perror(n &lt; 0 ? "stdin" : "stdout");
        exit(1);
}
</PRE>
                        <P>如果你在一个进程跟踪工具, 如 strace 下运行这个程序, 你可见到每个操作的成功或者失败, 
                        依赖是否当进行操作时有数据可用.</P></DIV>
                        <DIV class=footnotes><BR>
                        <HR align=left width=100>

                        <DIV class=footnote>
                        <P><SUP>[<A 
                        href="http://www.deansys.com/doc/ldd3/ch06s02.html#id436200" 
                        name=ftn.id436200><FONT color=#0000ff>22</FONT></A>] 
                        </SUP>它有一个想象的名子 default_wake_function.</P>
                        <DIV class=sect1 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H2 class=title style="CLEAR: both"><A 
                        name=pollandselect.sect1></A>6.3.&nbsp;poll 和 
                        select</H2></DIV></DIV></DIV>
                        <P>使用非阻塞 I/O 的应用程序常常使用 poll, select, 和 epoll 系统调用. poll, 
                        select 和 epoll 本质上有相同的功能: 
                        每个允许一个进程来决定它是否可读或者写一个或多个文件而不阻塞. 
                        这些调用也可阻塞进程直到任何一个给定集合的文件描述符可用来读或写. 因此, 
                        它们常常用在必须使用多输入输出流的应用程序, 而不必粘连在它们任何一个上. 相同的功能常常由多个函数提供, 因为 
                        2 个是由不同的团队在几乎相同时间完成的: select 在 BSD Unix 中引入, 而 poll 是 
                        System V 的解决方案. epoll 调用<SUP>[<A 
                        href="http://www.deansys.com/doc/ldd3/ch06s03.html#ftn.id436502" 
                        name=id436502><FONT 
                        color=#0000ff>23</FONT></A>]</SUP>添加在 2.5.45, 
                        作为使查询函数扩展到几千个文件描述符的方法.</P>
                        <P>支持任何一个这些调用都需要来自设备驱动的支持. 这个支持(对所有 3 个调用)由驱动的 poll 
                        方法调用. 这个方法由下列的原型:</P><PRE class=programlisting>unsigned int (*poll) (struct file *filp, poll_table *wait); 
</PRE>
                        <P>这个驱动方法被调用, 无论何时用户空间程序进行一个 poll, select, 或者 epoll 
                        系统调用, 涉及一个和驱动相关的文件描述符. 这个设备方法负责这 2 步:</P>
                        <DIV class=itemizedlist>
                        <UL type=disc>
                          <LI>
                          <P>1. 在一个或多个可指示查询状态变化的等待队列上调用 poll_wait. 如果没有文件描述符可用作 
                          I/O, 内核使这个进程在等待队列上等待所有的传递给系统调用的文件描述符. </P>
                          <LI>
                          <P>2. 返回一个位掩码, 描述可能不必阻塞就立刻进行的操作.</P></LI></UL></DIV>
                        <P>这 2 个操作常常是直接的, 并且趋向与各个驱动看起来类似. 但是, 它们依赖只能由驱动提供的信息, 
                        因此, 必须由每个驱动单独实现.</P>
                        <P>poll_table 结构, 给 poll 方法的第 2 个参数, 在内核中用来实现 poll, 
                        select, 和 epoll 调用; 它在 &lt;linux/poll.h&gt;中声明, 
                        这个文件必须被驱动源码包含. 驱动编写者不必要知道所有它内容并且必须作为一个不透明的对象使用它; 
                        它被传递给驱动方法以便驱动可用每个能唤醒进程的等待队列来加载它, 并且可改变 poll 操作状态. 
                        驱动增加一个等待队列到 poll_table 结构通过调用函数 poll_wait:</P><PRE class=programlisting> void poll_wait (struct file *, wait_queue_head_t *, poll_table *); 
</PRE>
                        <P>poll 方法的第 2 个任务是返回位掩码, 它描述哪个操作可马上被实现; 这也是直接的. 例如, 
                        如果设备有数据可用, 一个读可能不必睡眠而完成; poll 方法应当指示这个时间状态. 几个标志(通过 
                        &lt;linux/poll.h&gt; 定义)用来指示可能的操作:</P>
                        <DIV class=variablelist>
                        <DL>
                          <DT><SPAN class=term>POLLIN <SPAN></SPAN></SPAN>
                          <DD>
                          <P>如果设备可被不阻塞地读, 这个位必须设置.</P>
                          <DT><SPAN class=term>POLLRDNORM <SPAN></SPAN></SPAN>
                          <DD>
                          <P>这个位必须设置, 如果"正常"数据可用来读. 一个可读的设备返回( POLLIN|POLLRDNORM 
                          ).</P>
                          <DT><SPAN class=term>POLLRDBAND <SPAN></SPAN></SPAN>
                          <DD>
                          <P>这个位指示带外数据可用来从设备中读取. 当前只用在 Linux 内核的一个地方( DECnet 代码 
                          )并且通常对设备驱动不可用.</P>
                          <DT><SPAN class=term>POLLPRI <SPAN></SPAN></SPAN>
                          <DD>
                          <P>高优先级数据(带外)可不阻塞地读取. 这个位使 select 报告在文件上遇到一个异常情况, 因为 
                          selct 报告带外数据作为一个异常情况.</P>
                          <DT><SPAN class=term>POLLHUP<SPAN></SPAN></SPAN> 
                          <DD>
                          <P>当读这个设备的进程见到文件尾, 驱动必须设置 POLLUP(hang-up). 一个调用 select 
                          的进程被告知设备是可读的, 如同 selcet 功能所规定的.</P>
                          <DT><SPAN class=term>POLLERR <SPAN></SPAN></SPAN>
                          <DD>
                          <P>一个错误情况已在设备上发生. 当调用 poll, 设备被报告位可读可写, 
                          因为读写都返回一个错误码而不阻塞.</P>
                          <DT><SPAN class=term>POLLOUT <SPAN></SPAN></SPAN>
                          <DD>
                          <P>这个位在返回值中设置, 如果设备可被写入而不阻塞.</P>
                          <DT><SPAN class=term>POLLWRNORM<SPAN></SPAN></SPAN> 
                          <DD>
                          <P>这个位和 POLLOUT 有相同的含义, 并且有时它确实是相同的数. 一个可写的设备返回( 
                          POLLOUT|POLLWRNORM).</P>
                          <DT><SPAN class=term>POLLWRBAND<SPAN></SPAN></SPAN> 
                          <DD>
                          <P>如同 POLLRDBAND , 这个位意思是带有零优先级的数据可写入设备. 只有 poll 
                          的数据报实现使用这个位, 因为一个数据报看传送带外数据.</P></DD></DL></DIV>
                        <P>应当重复一下 POLLRDBAND 和 POLLWRBAND 仅仅对关联到 socket 
                        的文件描述符有意义: 通常设备驱动不使用这些标志.</P>
                        <P>poll 的描述使用了大量在实际使用中相对简单的东西. 考虑 poll 方法的 scullpipe 
                        实现:</P><PRE class=programlisting>static unsigned int scull_p_poll(struct file *filp, poll_table *wait)
{
        struct scull_pipe *dev = filp-&gt;private_data;
        unsigned int mask = 0;

        /*
        * The buffer is circular; it is considered full
        * if "wp" is right behind "rp" and empty if the
        * two are equal. 
        */
        down(&amp;dev-&gt;sem);
        poll_wait(filp, &amp;dev-&gt;inq,  wait);
        poll_wait(filp, &amp;dev-&gt;outq, wait);
        if (dev-&gt;rp != dev-&gt;wp)
                mask |= POLLIN | POLLRDNORM;  /* readable */
        if (spacefree(dev))
                mask |= POLLOUT | POLLWRNORM;  /* writable */
        up(&amp;dev-&gt;sem);
        return mask;
}
</PRE>
                        <P>这个代码简单地增加了 2 个 scullpipe 等待队列到 poll_table, 
                        接着设置正确的掩码位, 根据数据是否可以读或写.</P>
                        <P>所示的 poll 代码缺乏文件尾支持, 因为 scullpipe 不支持文件尾情况. 对大部分真实的设备, 
                        poll 方法应当返回 POLLHUP 如果没有更多数据(或者将)可用. 如果调用者使用 select 
                        系统调用, 文件被报告为可读. 不管是使用 poll 还是 select, 应用程序知道它能够调用 read 
                        而不必永远等待, 并且 read 方法返回 0 来指示文件尾.</P>
                        <P>例如, 对于 真正的FIFO, 读者见到一个文件尾当所有的写者关闭文件, 而在 scullpipe 
                        中读者永远见不到文件尾. 这个做法不同是因为 FIFO 是用作一个 2 个进程的通讯通道, 而 
                        scullpipe 是一个垃圾桶, 人人都可以放数据只要至少有一个读者. 更多地, 
                        重新实现内核中已有的东西是没有意义的, 因此我们选择在我们的例子里实现一个不同的做法.</P>
                        <P>与 FIFO 相同的方式实现文件尾就意味着检查 dev-&gt;nwwriters, 在 read 和 
                        poll 中, 并且报告文件尾(如刚刚描述过的)如果没有进程使设备写打开. 不幸的是, 使用这个实现方法, 
                        如果一个读者打开 scullpipe 设备在写者之前, 它可能见到文件尾而没有机会来等待数据. 
                        解决这个问题的最好的方式是在 open 中实现阻塞, 如同真正的 FIFO 所做的; 
                        这个任务留作读者的一个练习.</P>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=Interactionwithreadandwrite.sect2></A>6.3.1.&nbsp;与 
                        read 和 write 的交互</H3></DIV></DIV></DIV>
                        <P>poll 和 select 调用的目的是提前决定是否一个 I/O 操作会阻塞. 在那个方面, 它们补充了 
                        read 和 write. 更重要的是, poll 和 select , 因为它们使应用程序同时等待几个数据流, 
                        尽管我们在 scull 例子里没有采用这个特性.</P>
                        <P>一个正确的实现对于使应用程序正确工作是必要的: 尽管下列的规则或多或少已经说明过, 
                        我们在此总结它们.</P>
                        <DIV class=sect3 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H4 class=title><A 
                        name=Readingdatafromthedevice.sect3></A>6.3.1.1.&nbsp;从设备中读数据</H4></DIV></DIV></DIV>
                        <DIV class=itemizedlist>
                        <UL type=disc>
                          <LI>
                          <P>如果在输入缓冲中有数据, read 调用应当立刻返回, 没有可注意到的延迟, 
                          即便数据少于应用程序要求的, 并且驱动确保其他的数据会很快到达. 你可一直返回小于你被请求的数据, 
                          如果因为任何理由而方便这样(我们在 scull 中这样做), 如果你至少返回一个字节. 在这个情况下, 
                          poll 应当返回 POLLIN|POLLRDNORM.</P>
                          <LI>
                          <P>如果在输入缓冲中没有数据, 缺省地 read 必须阻塞直到有一个字节. 如果 O_NONBLOCK 
                          被置位, 另一方面, read 立刻返回 -EAGIN (尽管一些老版本 SYSTEM V 返回 0 
                          在这个情况时). 在这些情况中, poll 必须报告这个设备是不可读的直到至少一个字节到达. 
                          一旦在缓冲中有数据, 我们就回到前面的情况.</P>
                          <LI>
                          <P>如果我们处于文件尾, read 应当立刻返回一个 0, 不管是否阻塞. 这种情况 poll 应该报告 
                          POLLHUP.</P></LI></UL></DIV></DIV>
                        <DIV class=sect3 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H4 class=title><A 
                        name=Writingtothedevice.sect3></A>6.3.1.2.&nbsp;写入设备</H4></DIV></DIV></DIV>
                        <DIV class=itemizedlist>
                        <UL type=disc>
                          <LI>
                          <P>如果在输出缓冲中有空间, write 应当不延迟返回. 它可接受小于这个调用所请求的数据, 
                          但是它必须至少接受一个字节. 在这个情况下, poll 报告这个设备是可写的, 通过返回 
                          POLLOUT|POLLWRNORM.</P>
                          <LI>
                          <P>如果输出缓冲是满的, 缺省地 write 阻塞直到一些空间被释放. 如果 O_NOBLOCK 被设置, 
                          write 立刻返回一个 -EAGAIN(老式的 System V Unices 返回 0). 
                          在这些情况下, poll 应当报告文件是不可写的. 另一方面, 如果设备不能接受任何多余数据, write 
                          返回 -ENOSPC("设备上没有空间"), 不管是否设置了 O_NONBLOCK.</P>
                          <LI>
                          <P>在返回之前不要调用 wait 来传送数据, 即便当 O_NONBLOCK 被清除. 
                          这是因为许多应用程序选择来找出一个 write 是否会阻塞. 如果设备报告可写, 调用必须不阻塞. 
                          如果使用设备的程序想保证它加入到输出缓冲中的数据被真正传送, 驱动必须提供一个 fsync 方法. 例如, 
                          一个可移除的设备应当有一个 fsnyc 入口.</P></LI></UL></DIV>
                        <P>尽管有一套通用的规则, 还应当认识到每个设备是唯一的并且有时这些规则必须稍微弯曲一下. 例如, 
                        面向记录的设备(例如磁带设备)无法执行部分写.</P></DIV>
                        <DIV class=sect3 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H4 class=title><A 
                        name=Flushingpendingoutput.sect3></A>6.3.1.3.&nbsp;刷新挂起的输出</H4></DIV></DIV></DIV>
                        <P>我们已经见到 write 方法如何自己不能解决全部的输出需要. fsync 函数, 
                        由同名的系统调用而调用, 填补了这个空缺. 这个方法原型是:</P><PRE class=programlisting> int (*fsync) (struct file *file, struct dentry *dentry, int datasync); 
</PRE>
                        <P>如果一些应用程序需要被确保数据被发送到设备, fsync 方法必须被实现为不管 O_NONBLOCK 
                        是否被设置. 对 fsync 的调用应当只在设备被完全刷新时返回(即, 输出缓冲为空), 即便这需要一些时间. 
                        datasync 参数用来区分 fsync 和 fdatasync 系统调用; 这样, 它只对文件系统代码有用, 
                        驱动可以忽略它.</P>
                        <P>fsync 方法没有不寻常的特性. 这个调用不是时间关键的, 因此每个设备驱动可根据作者的口味实现它. 
                        大部分的时间, 字符驱动只有一个 NULL 指针在它们的 fops 中. 阻塞设备, 另一方面, 
                        常常实现这个方法使用通用的 block_fsync, 
它接着会刷新设备的所有的块.</P></DIV></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=TheUnderlyingDataStructure.sect2></A>6.3.2.&nbsp;底层的数据结构</H3></DIV></DIV></DIV>
                        <P>poll 和 select 系统调用的真正实现是相当地简单, 对那些感兴趣于它如何工作的人; epoll 
                        更加复杂一点但是建立在同样的机制上. 无论何时用户应用程序调用 poll, select, 或者 
                        epoll_ctl,<SUP>[<A 
                        href="http://www.deansys.com/doc/ldd3/ch06s03.html#ftn.id437076" 
                        name=id437076><FONT color=#0000ff>24</FONT></A>]</SUP> 
                        内核调用这个系统调用所引用的所有文件的 poll 方法, 传递相同的 poll_table 到每个. 
                        poll_table 结构只是对一个函数的封装, 这个函数建立了实际的数据结构. 那个数据结构, 对于 
                        poll和 select, 是一个内存页的链表, 其中包含 poll_table_entry 结构. 每个 
                        poll_table_entry 持有被传递给 poll_wait 的 struct file 和 
                        wait_queue_head_t 指针, 以及一个关联的等待队列入口. 对 poll_wait 
                        的调用有时还添加这个进程到给定的等待队列. 整个的结构必须由内核维护以至于这个进程可被从所有的队列中去除, 在 
                        poll 或者 select 返回之前.</P>
                        <P>如果被轮询的驱动没有一个指示 I/O 可不阻塞地发生, poll 
                        调用简单地睡眠直到一个它所在的等待队列(可能许多)唤醒它.</P>
                        <P>在 poll 实现中有趣的是驱动的 poll 方法可能被用一个 NULL 指针作为 poll_table 
                        参数. 这个情况出现由于几个理由. 如果调用 poll 的应用程序已提供了一个 0 
                        的超时值(指示不应当做等待), 没有理由来堆积等待队列, 并且系统简单地不做它. poll_table 
                        指针还被立刻设置为 NULL 在任何被轮询的驱动指示可以 I/O 之后. 因为内核在那一点知道不会发生等待, 
                        它不建立等待队列链表.</P>
                        <P>当 poll 调用完成, poll_table 结构被去分配, 并且所有的之前加入到 poll 
                        表的等待队列入口被从表和它们的等待队列中移出.</P>
                        <P>我们试图在图<A title="图&nbsp;6.1.&nbsp;poll 背后的数据结构" 
                        href="http://www.deansys.com/doc/ldd3/ch06s03.html#ldd3-6-1.fig"><FONT 
                        color=#0000ff>poll 背后的数据结构</FONT></A>中展示包含在轮询中的数据结构; 
                        这个图是真实数据结构的简化地表示, 因为它忽略了一个 poll 表地多页性质并且忽略了每个 
                        poll_table_entry 的文件指针.</P>
                        <DIV class=figure><A name=ldd3-6-1.fig></A>
                        <P class=title><B>图&nbsp;6.1.&nbsp;poll 背后的数据结构</B></P>
                        <DIV><IMG alt="poll 背后的数据结构" 
                        src="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/ldd3-6-1.png"></DIV></DIV>
                        <P>在此, 可能理解在新的系统调用 epoll 后面的动机. 在一个典型的情况中, 一个对 poll 或者 
                        select 的调用只包括一组文件描述符, 所以设置数据结构的开销是小的. 但是, 有应用程序在那里, 
                        它们使用几千个文件描述符. 在这时, 在每次 I/O 操作之间设置和销毁这个数据结构变得非常昂贵. epoll 
                        系统调用家族允许这类应用程序建立内部的内核数据结构只一次, 并且多次使用它们.</P></DIV>
                        <DIV class=footnotes><BR>
                        <HR align=left width=100>

                        <DIV class=footnote>
                        <P><SUP>[<A 
                        href="http://www.deansys.com/doc/ldd3/ch06s03.html#id436502" 
                        name=ftn.id436502><FONT color=#0000ff>23</FONT></A>] 
                        </SUP>实际上, epoll 是一组 3 个调用, 都可用来获得查询功能. 但是, 由于我们的目的, 
                        我们可认为它是一个调用.</P></DIV>
                        <DIV class=footnote>
                        <P><SUP>[<A 
                        href="http://www.deansys.com/doc/ldd3/ch06s03.html#id437076" 
                        name=ftn.id437076><FONT color=#0000ff>24</FONT></A>] 
                        </SUP>这是建立内部数据结构为将来调用 epoll_wait 的函数.</P>
                        <DIV class=sect1 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H2 class=title style="CLEAR: both"><A 
                        name=AsynchronousNotification.sect1></A>6.4.&nbsp;异步通知</H2></DIV></DIV></DIV>
                        <P>尽管阻塞和非阻塞操作和 select 方法的结合对于查询设备在大部分时间是足够的, 
                        一些情况还不能被我们迄今所见到的技术来有效地解决.</P>
                        <P>让我们想象一个进程, 在低优先级上执行一个长计算循环, 但是需要尽可能快的处理输入数据. 
                        如果这个进程在响应新的来自某些数据获取外设的报告, 它应当立刻知道当新数据可用时. 这个应用程序可能被编写来调用 
                        poll 有规律地检查数据, 但是, 对许多情况, 有更好的方法. 通过使能异步通知, 
                        这个应用程序可能接受一个信号无论何时数据可用并且不需要让自己去查询.</P>
                        <P>用户程序必须执行 2 个步骤来使能来自输入文件的异步通知. 首先, 它们指定一个进程作为文件的拥有者. 
                        当一个进程使用 fcntl 系统调用发出 F_SETOWN 命令, 这个拥有者进程的 ID 被保存在 
                        filp-&gt;f_owner 给以后使用. 这一步对内核知道通知谁是必要的. 为了真正使能异步通知, 
                        用户程序必须设置 FASYNC 标志在设备中, 通过 F_SETFL fcntl 命令.</P>
                        <P>在这 2 个调用已被执行后, 输入文件可请求递交一个 SIGIO 信号, 无论何时新数据到达. 
                        信号被发送给存储于 filp-&gt;f_owner 中的进程(或者进程组, 如果值为负值).</P>
                        <P>例如, 下面的用户程序中的代码行使能了异步的通知到当前进程, 给 stdin 输入文件:</P><PRE class=programlisting>signal(SIGIO, &amp;input_handler); /* dummy sample; sigaction() is better */
fcntl(STDIN_FILENO, F_SETOWN, getpid());
oflags = fcntl(STDIN_FILENO, F_GETFL);
fcntl(STDIN_FILENO, F_SETFL, oflags | FASYNC);
</PRE>
                        <P>这个在源码中名为 asynctest 的程序是一个简单的程序, 读取 stdin. 它可用来测试 
                        scullpipe 的异步能力. 这个程序和 cat 类似但是不结束于文件尾; 它只响应输入, 
                        而不是没有输入.</P>
                        <P>注意, 但是, 不是所有的设备都支持异步通知, 并且你可选择不提供它. 应用程序常常假定异步能力只对 
                        socket 和 tty 可用.</P>
                        <P>输入通知有一个剩下的问题. 当一个进程收到一个 SIGIO, 它不知道哪个输入文件有新数据提供. 
                        如果多于一个文件被使能异步地通知挂起输入的进程, 应用程序必须仍然靠 poll 或者 select 
                        来找出发生了什么.</P>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=TheDriversPointofView.sect2></A>6.4.1.&nbsp;驱动的观点</H3></DIV></DIV></DIV>
                        <P>对我们来说一个更相关的主题是设备驱动如何实现异步信号. 下面列出了详细的操作顺序, 从内核的观点:</P>
                        <DIV class=itemizedlist>
                        <UL type=disc>
                          <LI>
                          <P>1. 当发出 F_SETOWN, 什么都没发生, 除了一个值被赋值给 
                          filp-&gt;f_owner.</P>
                          <LI>
                          <P>2. 当 F_SETFL 被执行来打开 FASYNC, 驱动的 fasync 方法被调用. 
                          这个方法被调用无论何时 FASYNC 的值在 filp-&gt;f_flags 中被改变来通知驱动这个变化, 
                          因此它可正确地响应. 这个标志在文件被打开时缺省地被清除. 我们将看这个驱动方法的标准实现, 
在本节.</P>
                          <LI>
                          <P>3. 当数据到达, 所有的注册异步通知的进程必须被发出一个 SIGIO 
                        信号.</P></LI></UL></DIV>
                        <P>虽然实现第一步是容易的--在驱动部分没有什么要做的--其他的步骤包括维护一个动态数据结构来跟踪不同的异步读者; 
                        可能有几个. 这个动态数据结构, 但是, 不依赖特殊的设备, 
                        并且内核提供了一个合适的通用实现这样你不必重新编写同样的代码给每个驱动.</P>
                        <P>Linux 提供的通用实现是基于一个数据结构和 2 个函数(它们在前面所说的第 2 步和第 3 
                        步被调用). 声明相关材料的头文件是&lt;linux/fs.h&gt;(这里没新东西), 并且数据结构被称为 
                        struct fasync_struct. 至于等待队列, 我们需要插入一个指针在设备特定的数据结构中.</P>
                        <P>驱动调用的 2 个函数对应下面的原型:</P><PRE class=programlisting>int fasync_helper(int fd, struct file *filp, int mode, struct fasync_struct **fa);
void kill_fasync(struct fasync_struct **fa, int sig, int band);
</PRE>
                        <P>fasync_helper 被调用来从相关的进程列表中添加或去除入口项, 当 FASYNC 
                        标志因一个打开文件而改变. 它的所有参数除了最后一个, 都被提供给 fasync 方法并且被直接传递. 
                        当数据到达时 kill_fasync 被用来通知相关的进程. 它的参数是被传递的信号(常常是 SIGIO)和 
                        band, 这几乎都是 POLL_IN<SUP>[<A 
                        href="http://www.deansys.com/doc/ldd3/ch06s04.html#ftn.id437432" 
                        name=id437432><FONT 
                        color=#0000ff>25</FONT></A>]</SUP>(但是这可用来发送"紧急"或者带外数据, 
                        在网络代码里).</P>
                        <P>这是 scullpipe 如何实现 fasync 方法的:</P><PRE class=programlisting>static int scull_p_fasync(int fd, struct file *filp, int mode)
{
 struct scull_pipe *dev = filp-&gt;private_data;
 return fasync_helper(fd, filp, mode, &amp;dev-&gt;async_queue);
}
</PRE>
                        <P>显然所有的工作都由 fasync_helper 进行. 但是, 
                        不可能实现这个功能在没有一个方法在驱动里的情况下, 因为这个帮忙函数需要存取正确的指向 struct 
                        fasync_struct (这里是 与dev-&gt;async_queue)的指针, 
                        并且只有驱动可提供这个信息.</P>
                        <P>当数据到达, 下面的语句必须被执行来通知异步读者. 因为对 sucllpipe 读者的新数据通过一个发出 
                        write 的进程被产生, 这个语句出现在 scullpipe 的 write 方法中.</P><PRE class=programlisting>if (dev-&gt;async_queue)
 kill_fasync(&amp;dev-&gt;async_queue, SIGIO, POLL_IN);
</PRE>
                        <P>注意, 一些设备还实现异步通知来指示当设备可被写入时; 在这个情况, 当然, kill_fasnyc 
                        必须被使用一个 POLL_OUT 模式来调用.</P>
                        <P>可能会出现我们已经完成但是仍然有一件事遗漏. 我们必须调用我们的 fasync 方法, 
                        当文件被关闭来从激活异步读者列表中去除文件. 尽管这个调用仅当 filp-&gt;f_flags 被设置为 
                        FASYNC 时需要, 调用这个函数无论如何不会有问题并且是常见的实现. 下面的代码行, 例如, 是 
                        scullpipe 的 release 方法的一部分:</P><PRE class=programlisting>/* remove this filp from the asynchronously notified filp's */
scull_p_fasync(-1, filp, 0);
</PRE>
                        <P>这个在异步通知之下的数据结构一直和结构 struct wait_queue 是一致的, 因为 2 
                        种情况都涉及等待一个事件. 区别是这个 struct file 被用来替代 struct 
                        task_struct. 队列中的结构 file 接着用来存取 f_owner, 
                        为了通知进程.</P></DIV>
                        <DIV class=footnotes><BR>
                        <HR align=left width=100>

                        <DIV class=footnote>
                        <P><SUP>[<A 
                        href="http://www.deansys.com/doc/ldd3/ch06s04.html#id437432" 
                        name=ftn.id437432><FONT color=#0000ff>25</FONT></A>] 
                        </SUP>POLL_IN 是一个符号, 用在异步通知代码中; 它等同于 
                        POLLIN|POLLRDNORM.</P>
                        <DIV class=sect1 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H2 class=title style="CLEAR: both"><A 
                        name=SeekingaDevice.sect1></A>6.5.&nbsp;移位一个设备</H2></DIV></DIV></DIV>
                        <P>本章最后一个需要我们涉及的东西是 llseek 方法, 它有用(对于某些设备)并且容易实现.</P>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=ThellseekImplementation.sect2></A>6.5.1.&nbsp;llseek 
                        实现</H3></DIV></DIV></DIV>
                        <P>llseek 方法实现了 lseek 和 llseek 系统调用. 我们已经说了如果 llseek 
                        方法从设备的操作中缺失, 内核中的缺省的实现进行移位通过修改 filp-&gt;f_pos, 
                        这是文件中的当前读写位置. 请注意对于 lseek 系统调用要正确工作, 读和写方法必须配合, 
                        通过使用和更新它们收到的作为的参数的 offset 项.</P>
                        <P>你可能需要提供你自己的方法, 如果移位操作对应一个在设备上的物理操作. 一个简单的例子可在 scull 
                        驱动中找到:</P><PRE class=programlisting>loff_t scull_llseek(struct file *filp, loff_t off, int whence)
{
        struct scull_dev *dev = filp-&gt;private_data;
        loff_t newpos;

        switch(whence)
        {
        case 0: /* SEEK_SET */
                newpos = off;
                break;

        case 1: /* SEEK_CUR */
                newpos = filp-&gt;f_pos + off;
                break;

        case 2: /* SEEK_END */
                newpos = dev-&gt;size + off;
                break;

        default: /* can't happen */
                return -EINVAL;
        }
        if (newpos &lt; 0)
                return -EINVAL;
        filp-&gt;f_pos = newpos;
        return newpos;
}
</PRE>
                        <P>唯一设备特定的操作是从设备中获取文件长度. 在 scull 中 read 和 write 
                        方法如需要地一样协作, 如同在第 3 章所示.</P>
                        <P>尽管刚刚展示的这个实现对 scull 有意义, 它处理一个被很好定义了的数据区, 
                        大部分设备提供了一个数据流而不是一个数据区(想想串口或者键盘), 并且移位这些设备没有意义. 
                        如果这就是你的设备的情况, 你不能只制止声明 llseek 操作, 因为缺省的方法允许移位. 相反, 
                        你应当通知内核你的设备不支持 llseek , 通过调用 nonseekable_open 在你的 open 
                        方法中.</P><PRE class=programlisting>int nonseekable_open(struct inode *inode; struct file *filp); 
</PRE>
                        <P>这个调用标识了给定的 filp 为不可移位的; 内核从不允许一个 lseek 调用在这样一个文件上成功. 
                        通过用这样的方式标识这个文件, 你可确定不会有通过 pread 和 pwrite 
                        系统调用的方式来试图移位这个文件.</P>
                        <P>完整起见, 你也应该在你的 file_operations 结构中设置 llseek 
                        方法到一个特殊的帮忙函数 no_llseek, 它定义在 &lt;linux/fs.h&gt;. </P>
                        <DIV class=sect1 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H2 class=title style="CLEAR: both"><A 
                        name=AccessControlonaDeviceFile.sect1></A>6.6.&nbsp;在一个设备文件上的存取控制</H2></DIV></DIV></DIV>
                        <P>提供存取控制对于一个设备节点来说有时是至关重要的. 
                        不仅是非授权用户不能使用设备(由文件系统许可位所强加的限制), 
                        而且有时只有授权用户才应当被允许来打开设备一次.</P>
                        <P>这个问题类似于使用 ttys 的问题. 在那个情况下, login 进程改变设备节点的所有权, 
                        无论何时一个用户登录到系统, 为了阻止其他的用户打扰或者偷听这个 tty 的数据流. 但是, 
                        仅仅为了保证对它的唯一读写而使用一个特权程序在每次打开它时改变一个设备的拥有权是不实际的. </P>
                        <P>迄今所显示的代码没有实现任何的存取控制, 除了文件系统许可位. 如果系统调用 open 将请求递交给驱动, 
                        open 就成功了. 我们现在介绍几个新技术来实现一些额外的检查.</P>
                        <P>每个在本节中展示的设备有和空的 scull 设备有相同的行为(即, 
                        它实现一个持久的内存区)但是在存取控制方面和 scull 不同, 这个实现在 open 和 release 
                        操作中.</P>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=SingleOpenDevices.sect2></A>6.6.1.&nbsp;单 open 
                        设备</H3></DIV></DIV></DIV>
                        <P>提供存取控制的强力方式是只允许一个设备一次被一个进程打开(单次打开). 
                        这个技术最好是避免因为它限制了用户的灵活性. 一个用户可能想运行不同的进程在一个设备上, 
                        一个读状态信息而另一个写数据. 在某些情况下, 用户通过一个外壳脚本运行几个简单的程序可做很多事情, 
                        只要它们可并发存取设备. 换句话说, 实现一个单 open 行为实际是在创建策略, 
                        这样可能会介入你的用户要做的范围.</P>
                        <P>只允许单个进程打开设备有不期望的特性, 但是它也是一个设备驱动最简单实现的存取控制, 因此它在这里被展示. 
                        这个源码是从一个称为 scullsingle 的设备中提取的.</P>
                        <P>scullsingle 设备维护一个 atiomic_t 变量, 称为 
                        scull_s_available; 这个变量被初始化为值 1, 表示设备确实可用. open 调用递减并测试 
                        scull_s_available 并拒绝存取如果其他人已经使设备打开.</P><PRE class=programlisting>static atomic_t scull_s_available = ATOMIC_INIT(1);
static int scull_s_open(struct inode *inode, struct file *filp)
{

        struct scull_dev *dev = &amp;scull_s_device; /* device information */
        if (! atomic_dec_and_test (&amp;scull_s_available))
        {
                atomic_inc(&amp;scull_s_available);
                return -EBUSY; /* already open */
        }

        /* then, everything else is copied from the bare scull device */
        if ( (filp-&gt;f_flags &amp; O_ACCMODE) == O_WRONLY)

                scull_trim(dev);
        filp-&gt;private_data = dev;
        return 0; /* success */
}
</PRE>
                        <P>release 调用, 另一方面, 标识设备为不再忙:</P><PRE class=programlisting>static int scull_s_release(struct inode *inode, struct file *filp)
{
        atomic_inc(&amp;scull_s_available); /* release the device */
        return 0;
}
</PRE>
                        <P>正常地, 我们建议你将 open 标志 scul_s_available 放在设备结构中( 
                        scull_dev 这里), 因为, 从概念上, 它属于这个设备. scull 驱动, 但是, 
                        使用独立的变量来保持这个标志, 因此它可使用和空 scull 设备同样的设备结构和方法, 
                        并且最少的代码复制.</P></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=RestrictingAccesstoaSingleUserataTime.sect2></A>6.6.2.&nbsp;一次对一个用户限制存取</H3></DIV></DIV></DIV>
                        <P>单打开设备之外的下一步是使一个用户在多个进程中打开一个设备, 但是一次只允许一个用户打开设备. 
                        这个解决方案使得容易测试设备, 因为用户一次可从几个进程读写, 
                        但是假定这个用户负责维护在多次存取中的数据完整性. 这通过在 open 方法中添加检查来实现; 
                        这样的检查在通常的许可检查后进行, 并且只能使存取更加严格, 比由拥有者和组许可位所指定的限制. 这是和 
                        ttys 所用的存取策略是相同的, 但是它不依赖于外部的特权程序.</P>
                        <P>这些存取策略实现地有些比单打开策略要奇怪. 在这个情况下, 需要 2 项: 一个打开计数和设备拥有者 
                        uid. 再一次, 给这个项的最好的地方是在设备结构中; 我们的例子使用全局变量代替, 是因为之前为 
                        scullsingle 所解释的的原因. 这个设备的名子是 sculluid.</P>
                        <P>open 调用在第一次打开时同意了存取但是记住了设备拥有者. 这意味着一个用户可打开设备多次, 
                        因此允许协调多个进程对设备并发操作. 同时, 没有其他用户可打开它, 这样避免了外部干扰. 
                        因为这个函数版本几乎和之前的一致, 这样相关的部分在这里被复制:</P><PRE class=programlisting>spin_lock(&amp;scull_u_lock);
if (scull_u_count &amp;&amp;
                (scull_u_owner != current-&gt;uid) &amp;&amp; /* allow user */
                (scull_u_owner != current-&gt;euid) &amp;&amp; /* allow whoever did su */
                !capable(CAP_DAC_OVERRIDE))
{ /* still allow root */
        spin_unlock(&amp;scull_u_lock);
        return -EBUSY; /* -EPERM would confuse the user */
}

if (scull_u_count == 0)
        scull_u_owner = current-&gt;uid; /* grab it */

scull_u_count++;
spin_unlock(&amp;scull_u_lock);
</PRE>
                        <P>注意 sculluid 代码有 2 个变量 ( scull_u_owner 和 
                        scull_u_count)来控制对设备的存取, 并且这样可被多个进程并发地存取. 为使这些变量安全, 
                        我们使用一个自旋锁控制对它们的存取( scull_u_lock ). 没有这个锁, 2 
                        个(或多个)进程可同时测试 scull_u_count , 并且都可能认为它们拥有设备的拥有权. 
                        这里使用一个自旋锁, 是因为这个锁被持有极短的时间, 并且驱动在持有这个锁时不做任何可睡眠的事情.</P>
                        <P>我们选择返回 -EBUSY 而不是 -EPERM, 即便这个代码在进行许可检测, 
                        为了给一个被拒绝存取的用户指出正确的方向. 对于"许可拒绝"的反应常常是检查 /dev 文件的模式和拥有者, 
                        而"设备忙"正确地建议用户应当寻找一个已经在使用设备的进程.</P>
                        <P>这个代码也检查来看是否正在试图打开的进程有能力来覆盖文件存取许可; 如果是这样, open 
                        被允许即便打开进程不是设备的拥有者. CAP_DAC_OVERRIDE 能力在这个情况中适合这个任务.</P>
                        <P>release 方法看来如下:</P><PRE class=programlisting>static int scull_u_release(struct inode *inode, struct file *filp)
{
        spin_lock(&amp;scull_u_lock);
        scull_u_count--; /* nothing else */
        spin_unlock(&amp;scull_u_lock);
        return 0;
}
</PRE>
                        <P>再次, 我们在修改计数之前必须获得锁, 来确保我们没有和另一个进程竞争.</P></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=BlockingopenasanAlternativetoEBUSY.sect2></A>6.6.3.&nbsp;阻塞 
                        open 作为对 EBUSY 的替代</H3></DIV></DIV></DIV>
                        <P>当设备不可存取, 返回一个错误常常是最合理的方法, 但是有些情况用户可能更愿意等待设备.</P>
                        <P>例如, 如果一个数据通讯通道既用于规律地预期地传送报告(使用 crontab), 
                        也用于根据用户的需要偶尔地使用, 对于被安排的操作最好是稍微延迟, 而不是只是因为通道当前忙而失败.</P>
                        <P>这是程序员在设计一个设备驱动时必须做的一个选择之一, 并且正确的答案依赖正被解决的实际问题.</P>
                        <P>对 EBUSY 的替代, 如同你可能已经想到的, 是实现阻塞 open. scullwuid 
                        设备是一个在打开时等待设备而不是返回 -EBUSY 的 sculluid 版本. 它不同于 sculluid 
                        只在下面的打开操作部分:</P><PRE class=programlisting>spin_lock(&amp;scull_w_lock);
while (! scull_w_available())
{
        spin_unlock(&amp;scull_w_lock);
        if (filp-&gt;f_flags &amp; O_NONBLOCK)
                return -EAGAIN;
        if (wait_event_interruptible (scull_w_wait, scull_w_available()))
                return -ERESTARTSYS; /* tell the fs layer to handle it */
        spin_lock(&amp;scull_w_lock);
}
if (scull_w_count == 0)
        scull_w_owner = current-&gt;uid; /* grab it */
scull_w_count++;
spin_unlock(&amp;scull_w_lock);
</PRE>
                        <P>这个实现再次基于一个等待队列. 如果设备当前不可用, 
                        试图打开它的进程被放置到等待队列直到拥有进程关闭设备.</P>
                        <P>release 方法, 接着, 负责唤醒任何挂起的进程:</P><PRE class=programlisting>static int scull_w_release(struct inode *inode, struct file *filp)
{

 int temp;
 spin_lock(&amp;scull_w_lock);
 scull_w_count--;
 temp = scull_w_count;
 spin_unlock(&amp;scull_w_lock); 
    if (temp == 0)
 wake_up_interruptible_sync(&amp;scull_w_wait); /* awake other uid's */
 return 0;
}
</PRE>
                        <P>这是一个例子, 这里调用 wake_up_interruptible_sync 是有意义的. 
                        当我们做这个唤醒, 我们只是要返回到用户空间, 这对于系统是一个自然的调度点. 
                        当我们做这个唤醒时不是潜在地重新调度, 最好只是调用 "sync" 版本并且完成我们的工作.</P>
                        <P>阻塞式打开实现的问题是对于交互式用户真的不好, 他们不得不猜想哪里出错了. 交互式用户常常调用标准命令, 
                        例如 cp 和 tar, 并且不能增加 O_NONBLOCK 到 open 调用. 
                        有些使用磁带驱动器做备份的人可能喜欢有一个简单的"设备或者资源忙"消息, 
                        来替代被扔在一边猜为什么今天的硬盘驱动器这么安静, 此时 tar 应当在扫描它.</P>
                        <P>这类的问题(需要一个不同的, 不兼容的策略对于同一个设备)最好通过为每个存取策略实现一个设备节点来实现. 
                        这个做法的一个例子可在 linux 磁带驱动中找到, 它提供了多个设备文件给同一个设备. 例如, 
                        不同的设备文件将使驱动器使用或者不用压缩记录, 或者自动回绕磁带当设备被关闭时.</P></DIV>
                        <DIV class=sect2 lang=zh-cn>
                        <DIV class=titlepage>
                        <DIV>
                        <DIV>
                        <H3 class=title><A 
                        name=CloningtheDeviceonopen.sect2></A>6.6.4.&nbsp;在 open 
                        时复制设备</H3></DIV></DIV></DIV>
                        <P>管理存取控制的另一个技术是创建设备的不同的私有拷贝, 根据打开它的进程.</P>
                        <P>明显地, 这只当设备没有绑定到一个硬件实体时有可能; scull 是一个这样的"软件"设备的例子. 
                        /dev/tty 的内部使用类似的技术来给它的进程一个不同的 /dev 入口点呈现的视图. 
                        当设备的拷贝被软件驱动创建, 我们称它们为虚拟设备--就象虚拟控制台使用一个物理 tty 设备.</P>
                        <P>结构这类的存取控制很少需要, 这个实现可说明内核代码是多么容易改变应用程序的对周围世界的看法(即, 
                        计算机).</P>
                        <P>/dev/scullpriv 设备节点在 scull 软件包只实现虚拟设备. scullpriv 
                        实现使用了进程的控制 tty 的设备号作为对存取虚拟设备的钥匙. 但是, 
                        你可以轻易地改变代码来使用任何整数值作为钥匙; 每个选择都导致一个不同的策略. 例如, 使用 uid 
                        导致一个不同地虚拟设备给每个用户, 而使用一个 pid 钥匙创建一个新设备为每个存取它的进程.</P>
                        <P>使用控制终端的决定打算用在易于使用 I/O 重定向测试设备: 
                        设备被所有的在同一个虚拟终端运行的命令所共享, 并且保持独立于在另一个终端上运行的命令所见到的.</P>
                        <P>open 方法看来象下面的代码. 它必须寻找正确的虚拟设备并且可能创建一个. 这个函数的最后部分没有展示, 
                        因为它拷贝自空的 scull, 我们已经见到过.</P><PRE class=programlisting>/* The clone-specific data structure includes a key field */
struct scull_listitem
{
        struct scull_dev device;
        dev_t key;
        struct list_head list;

};
/* The list of devices, and a lock to protect it */
static LIST_HEAD(scull_c_list);
static spinlock_t scull_c_lock = SPIN_LOCK_UNLOCKED;

/* Look for a device or create one if missing */
static struct scull_dev *scull_c_lookfor_device(dev_t key)
{

        struct scull_listitem *lptr;
        list_for_each_entry(lptr, &amp;scull_c_list, list)
        {
                if (lptr-&gt;key == key)
                        return &amp;(lptr-&gt;device);
        }

        /* not found */
        lptr = kmalloc(sizeof(struct scull_listitem), GFP_KERNEL);
        if (!lptr)
                return NULL;
        /* initialize the device */
        memset(lptr, 0, sizeof(struct scull_listitem));
        lptr-&gt;key = key;
        scull_trim(&amp;(lptr-&gt;device)); /* initialize it */
        init_MUTEX(&amp;(lptr-&gt;device.sem));

        /* place it in the list */
        list_add(&amp;lptr-&gt;list, &amp;scull_c_list);

        return &amp;(lptr-&gt;device);
}

static int scull_c_open(struct inode *inode, struct file *filp)
{
        struct scull_dev *dev;

        dev_t key;
        if (!current-&gt;signal-&gt;tty)
        {
                PDEBUG("Process \"%s\" has no ctl tty\n", current-&gt;comm);
                return -EINVAL;

        }
        key = tty_devnum(current-&gt;signal-&gt;tty);

        /* look for a scullc device in the list */
        spin_lock(&amp;scull_c_lock);
        dev = scull_c_lookfor_device(key);
        spin_unlock(&amp;scull_c_lock);

        if (!dev)
                return -ENOMEM;

        /* then, everything else is copied from the bare scull device */
</PRE>
                        <P>这个 release 方法没有做特殊的事情. 它将在最后的关闭时正常地释放设备, 但是我们不选择来维护一个 
                        open 计数而来简化对驱动的测试. 如果设备在最后的关闭被释放, 你将不能读相同的数据在写入设备之后, 
                        除非一个后台进程将保持它打开. 例子驱动采用了简单的方法来保持数据, 以便在下一次打开时, 你会发现它在那里. 
                        设备在 scull_cleanup 被调用时释放.</P>
                        <P>这个代码使用通用的 linux 链表机制, 而不是从头开始实现相同的功能. linux 链表在第 11 
                        章中讨论.</P>
                        <P>这里是 /dev/scullpriv 的 release 实现, 它结束了对设备方法的讨论.</P><PRE class=programlisting>static int scull_c_release(struct inode *inode, struct file *filp)
{
        /*
        *Nothing to do, because the device is persistent.
        *A `real' cloned device should be freed on last close */

        return 0;
}
</PRE><PRE class=programlisting><DIV class=titlepage><DIV><DIV><H2 class=title style="CLEAR: both"><A name=AdvancedCharDriverOperationsqr.sect1></A>6.7.&nbsp;快速参考</H2></DIV></DIV></DIV><P>本章介绍了下面的符号和头文件:</P><DIV class=variablelist><DL><DT><SPAN class=term><SPAN>#include &lt;linux/ioctl.h&gt;</SPAN></SPAN> <DD><P>声明用来定义 ioctl 命令的宏定义. 当前被 &lt;linux/fs.h&gt; 包含.</P><DT><SPAN class=term><SPAN>_IOC_NRBITS</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>_IOC_TYPEBITS</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>_IOC_SIZEBITS</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>_IOC_DIRBITS </SPAN></SPAN><DD><P>ioctl 命令的不同位段所使用的位数. 还有 4 个宏来指定 MASK 和 4 个指定 SHIFT, 但是它们主要是给内部使用. _IOC_SIZEBIT 是一个要检查的重要的值, 因为它跨体系改变.</P><DT><SPAN class=term><SPAN>_IOC_NONE</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>_IOC_READ</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>_IOC_WRITE </SPAN></SPAN><DD><P>"方向"位段可能的值. "read" 和 "write" 是不同的位并且可相或来指定 read/write. 这些值是基于 0 的.</P><DT><SPAN class=term><SPAN>_IOC(dir,type,nr,size)</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>_IO(type,nr)</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>_IOR(type,nr,size)</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>_IOW(type,nr,size)</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>_IOWR(type,nr,size)</SPAN></SPAN> <DD><P>用来创建 ioclt 命令的宏定义.</P><DT><SPAN class=term><SPAN>_IOC_DIR(nr)</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>_IOC_TYPE(nr)</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>_IOC_NR(nr)</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>_IOC_SIZE(nr)</SPAN></SPAN> <DD><P>用来解码一个命令的宏定义. 特别地, _IOC_TYPE(nr) 是 _IOC_READ 和 _IOC_WRITE 的 OR 结合.</P><DT><SPAN class=term><SPAN>#include &lt;asm/uaccess.h&gt;</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>int access_ok(int type, const void *addr, unsigned long size);</SPAN></SPAN> <DD><P>检查一个用户空间的指针是可用的. access_ok 返回一个非零值, 如果应当允许存取.</P><DT><SPAN class=term><SPAN>VERIFY_READ </SPAN></SPAN><DD><DT><SPAN class=term>VERIFY_WRITE <SPAN></SPAN></SPAN><DD><P>access_ok 中 type 参数的可能取值. VERIFY_WRITE 是 VERIFY_READ 的超集.</P><DT><SPAN class=term><SPAN>#include &lt;asm/uaccess.h&gt;</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>int put_user(datum,ptr);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>int get_user(local,ptr);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>int __put_user(datum,ptr);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>int __get_user(local,ptr);</SPAN></SPAN> <DD><P>用来存储或获取一个数据到或从用户空间的宏. 传送的字节数依赖 sizeof(*ptr). 常规的版本调用 access_ok , 而常规版本( __put_user 和 __get_user ) 假定 access_ok 已经被调用了.</P><DT><SPAN class=term><SPAN>#include &lt;linux/capability.h&gt;</SPAN></SPAN> <DD><P>定义各种 CAP_ 符号, 描述一个用户空间进程可有的能力.</P><DT><SPAN class=term><SPAN>int capable(int capability);</SPAN></SPAN> <DD><P>返回非零值如果进程有给定的能力.</P><DT><SPAN class=term><SPAN>#include &lt;linux/wait.h&gt;</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>typedef struct { /* ... */ } wait_queue_head_t;</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>void init_waitqueue_head(wait_queue_head_t *queue);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>DECLARE_WAIT_QUEUE_HEAD(queue);</SPAN></SPAN> <DD><P>Linux 等待队列的定义类型. 一个 wait_queue_head_t 必须被明确在运行时使用 init_waitqueue_head 或者编译时使用 DEVLARE_WAIT_QUEUE_HEAD 进行初始化.</P><DT><SPAN class=term><SPAN>void wait_event(wait_queue_head_t q, int condition);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>int wait_event_interruptible(wait_queue_head_t q, int condition);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>int wait_event_timeout(wait_queue_head_t q, int condition, int time);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>int wait_event_interruptible_timeout(wait_queue_head_t q, int condition,int time);</SPAN></SPAN> <DD><P>使进程在给定队列上睡眠, 直到给定条件值为真值.</P><DT><SPAN class=term><SPAN>void wake_up(struct wait_queue **q);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>void wake_up_interruptible(struct wait_queue **q);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>void wake_up_nr(struct wait_queue **q, int nr);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>void wake_up_interruptible_nr(struct wait_queue **q, int nr);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>void wake_up_all(struct wait_queue **q);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>void wake_up_interruptible_all(struct wait_queue **q);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>void wake_up_interruptible_sync(struct wait_queue **q);</SPAN></SPAN> <DD><P>唤醒在队列 q 上睡眠的进程. _interruptible 的形式只唤醒可中断的进程. 正常地, 只有一个互斥等待者被唤醒, 但是这个行为可被 _nr 或者 _all 形式所改变. _sync 版本在返回之前不重新调度 CPU.</P><DT><SPAN class=term><SPAN>#include &lt;linux/sched.h&gt;</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>set_current_state(int state);</SPAN></SPAN> <DD><P>设置当前进程的执行状态. TASK_RUNNING 意味着它已经运行, 而睡眠状态是 TASK_INTERRUPTIBLE 和 TASK_UNINTERRUPTIBLE.</P><DT><SPAN class=term><SPAN>void schedule(void);</SPAN></SPAN> <DD><P>选择一个可运行的进程从运行队列中. 被选中的进程可是当前进程或者另外一个.</P><DT><SPAN class=term><SPAN>typedef struct { /* ... */ } wait_queue_t;</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>init_waitqueue_entry(wait_queue_t *entry, struct task_struct *task);</SPAN></SPAN> <DD><P>wait_queue_t 类型用来放置一个进程到一个等待队列.</P><DT><SPAN class=term><SPAN>void prepare_to_wait(wait_queue_head_t *queue, wait_queue_t *wait, int state);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>void prepare_to_wait_exclusive(wait_queue_head_t *queue, wait_queue_t *wait, int state);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>void finish_wait(wait_queue_head_t *queue, wait_queue_t *wait);</SPAN></SPAN> <DD><P>帮忙函数, 可用来编码一个手工睡眠.</P><DT><SPAN class=term><SPAN>void sleep_on(wiat_queue_head_t *queue);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>void interruptible_sleep_on(wiat_queue_head_t *queue);</SPAN></SPAN> <DD><P>老式的不推荐的函数, 它们无条件地使当前进程睡眠.</P><DT><SPAN class=term><SPAN>#include &lt;linux/poll.h&gt;</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>void poll_wait(struct file *filp, wait_queue_head_t *q, poll_table *p);</SPAN></SPAN> <DD><P>将当前进程放入一个等待队列, 不立刻调度. 它被设计来被设备驱动的 poll 方法使用.</P><DT><SPAN class=term><SPAN>int fasync_helper(struct inode *inode, struct file *filp, int mode, struct fasync_struct **fa);</SPAN></SPAN> <DD><P>一个"帮忙者", 来实现 fasync 设备方法. mode 参数是传递给方法的相同的值, 而 fa 指针指向一个设备特定的 fasync_struct *.</P><DT><SPAN class=term><SPAN>void kill_fasync(struct fasync_struct *fa, int sig, int band);</SPAN></SPAN> <DD><P>如果这个驱动支持异步通知, 这个函数可用来发送一个信号到登记在 fa 中的进程.</P><DT><SPAN class=term><SPAN>int nonseekable_open(struct inode *inode, struct file *filp);</SPAN></SPAN> <DD><DT><SPAN class=term><SPAN>loff_t no_llseek(struct file *file, loff_t offset, int whence);</SPAN></SPAN> <DD><P>nonseekable_open 应当在任何不支持移位的设备的 open 方法中被调用. 这样的设备应当使用 no_llseek 作为它们的 llseek 方法.</P></DD></DL></DIV></PRE></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV></DIV>
                        <DIV></DIV></DIV></TD></TR></TBODY></TABLE>
                  <P style="MARGIN: 5px; LINE-HEIGHT: 150%"><A 
                  href="http://blog.chinaunix.net/u2/78225/showart.php?id=1270012" 
                  target=_blank>回目录 Linux Device Driver书籍</A> </P></TD></TR>
              <TR>
                <TD align=middle height=25><FONT color=#295200>发表于： 2008-09-28 
                  ，修改于： 2008-10-06 16:29，已浏览40次，有评论0条</FONT> <A id=star 
                  title=推荐这篇文章 onclick="NewWindows(this.href);return false;" 
                  href="http://blog.chinaunix.net/u2/star.php?blogid=78225&amp;artid=1270103">推荐</A> 
                  <A id=complaint title=投诉这篇文章 
                  onclick="NewWindows(this.href);return false;" 
                  href="http://blog.chinaunix.net/u2/complaint.php?blogid=78225&amp;artid=1270103">投诉</A> 
                </TD></TR></TBODY></TABLE></TD></TR></TBODY></TABLE></TD>
    <TD width=18 
    background="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/bg_art_right.gif"></TD></TR>
  <TR>
    <TD width=18 height=28><IMG alt="" 
      src="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/bg_art_left_bottom.gif" 
      border=0></TD>
    <TD 
    background="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/bg_art_bottom.gif">
      <P style="MARGIN: 5px; LINE-HEIGHT: 150%"></P></TD>
    <TD width=18 height=28><IMG alt="" 
      src="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/bg_art_right_bottom.gif" 
      border=0></TD></TR></TBODY></TABLE><BR>
<TABLE style="BORDER-COLLAPSE: collapse" borderColor=#a5bd6b cellSpacing=1 
cellPadding=0 width="90%" align=center border=1>
  <TBODY>
  <TR>
    <TD style="COLOR: #295200" bgColor=#eff7de height=25><B>网友评论</B></TD></TR>
  <TR>
    <TD bgColor=#ffffff height=1></TD></TR>
  <TR>
    <TD align=middle bgColor=#f9f5e7>
      <TABLE 
      style="COLOR: #295200; BORDER-COLLAPSE: collapse; WORD-WRAP: break-word" 
      cellSpacing=0 cellPadding=0 width="100%" align=center border=0>
        <TBODY></TBODY></TABLE></TD></TR></TBODY></TABLE><BR>
<TABLE style="BORDER-COLLAPSE: collapse" borderColor=#a5bd6b cellSpacing=1 
cellPadding=0 width="90%" align=center border=1>
  <TBODY>
  <TR>
    <TD style="COLOR: #295200" bgColor=#eff7de height=25><B>发表评论</B></TD></TR>
  <TR>
    <TD bgColor=#ffffff height=1></TD></TR>
  <TR>
    <TD align=middle bgColor=#f9f5e7><IFRAME name=comment 
      src="Linux Device Driver书籍（6）并发和竞争情况 - LDD3 - 嵌入式驱动进行时.files/comment.htm" 
      frameBorder=0 width="100%" 
height=160></IFRAME></TD></TR></TBODY></TABLE></BODY></HTML>
